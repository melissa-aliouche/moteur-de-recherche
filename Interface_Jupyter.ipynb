{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TD 8‚Äì10 : Moteur de recherche avec Jupyter\r\n",
    "\r\n",
    "Ce notebook regroupe les TD 8, 9 et 10.\r\n",
    "\r\n",
    "- **TD 8** : chargement du corpus, moteur de recherche et interface graphique avec ipywidgets.\r\n",
    "- **TD 9‚Äì10** : ajout de filtres, analyses du vocabulaire et exploration temporelle des mots.\r\n",
    "\r\n",
    "L‚Äôobjectif est de proposer une interface interactive pour explorer et analyser le corpus.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation des d√©pendances n√©cessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation des packages n√©cessaires\n",
    "!pip install pandas numpy scipy ipywidgets tqdm matplotlib seaborn plotly --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports des biblioth√®ques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import re\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "# Imports de vos classes personnalis√©es\n",
    "from Corpus import Corpus\n",
    "from Document import Document\n",
    "from DocumentFactory import DocumentFactory\n",
    "from SearchEngine import SearchEngine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Partie 1 : D√©marrage\n",
    "## 1.1 - R√©cup√©ration et chargement du jeu de donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aper√ßu des donn√©es :\n",
      "   id                                              titre  \\\n",
      "0   0       I switched to Machine Learning and I am LOST   \n",
      "1   1  Best resources to learn Machine Learning deepl...   \n",
      "2   2         Is machine learning a good career in 2025?   \n",
      "3   3             I hate \"my\" \"field\" (machine learning)   \n",
      "4   4                          Machine Learning Hiring üí™   \n",
      "\n",
      "                 auteur                 date  \\\n",
      "0           Hertz314159  2025-10-29 01:46:28   \n",
      "1              vansh596  2025-08-18 13:53:27   \n",
      "2          stanley_john  2025-08-13 13:07:19   \n",
      "3  Substantial-Art-2238  2025-04-17 10:23:23   \n",
      "4  Zealousideal_Bit_177  2025-09-13 12:32:36   \n",
      "\n",
      "                                                 url  \\\n",
      "0  https://reddit.com/r/learnmachinelearning/comm...   \n",
      "1  https://reddit.com/r/learnmachinelearning/comm...   \n",
      "2  https://reddit.com/r/learnmachinelearning/comm...   \n",
      "3  https://reddit.com/r/PhD/comments/1k17rbr/i_ha...   \n",
      "4  https://reddit.com/r/Btechtards/comments/1nfu6...   \n",
      "\n",
      "                                               texte    type  \n",
      "0  I switched to Machine Learning and I am LOST H...  Reddit  \n",
      "1  Best resources to learn Machine Learning deepl...  Reddit  \n",
      "2        Is machine learning a good career in 2025?   Reddit  \n",
      "3  I hate \"my\" \"field\" (machine learning) A lot o...  Reddit  \n",
      "4                         Machine Learning Hiring üí™   Reddit  \n",
      "\n",
      "Nombre total de documents : 10\n",
      "\n",
      "Colonnes disponibles : ['id', 'titre', 'auteur', 'date', 'url', 'texte', 'type']\n"
     ]
    }
   ],
   "source": [
    "# Chargement du fichier TSV\n",
    "df_discours = pd.read_csv('corpus.tsv', sep='\\t')\n",
    "\n",
    "print(\"Aper√ßu des donn√©es :\")\n",
    "print(df_discours.head())\n",
    "print(f\"\\nNombre total de documents : {len(df_discours)}\")\n",
    "print(f\"\\nColonnes disponibles : {list(df_discours.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 - V√©rification de la distribution des auteurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution des auteurs :\n",
      "auteur\n",
      "Hertz314159               1\n",
      "vansh596                  1\n",
      "stanley_john              1\n",
      "Substantial-Art-2238      1\n",
      "Zealousideal_Bit_177      1\n",
      "Cedric De Boom            1\n",
      "Ian Walsh                 1\n",
      "Felix Mohr                1\n",
      "Davide Cacciarelli        1\n",
      "Maximilian P Niroomand    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Nombre total d'auteurs uniques : 10\n"
     ]
    }
   ],
   "source": [
    "# Distribution des auteurs\n",
    "print(\"Distribution des auteurs :\")\n",
    "print(df_discours['auteur'].value_counts())\n",
    "\n",
    "print(f\"\\nNombre total d'auteurs uniques : {df_discours['auteur'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 - Cr√©ation du corpus avec d√©coupage en phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cr√©ation du corpus avec d√©coupage en phrases...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traitement: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 4977.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Corpus 'Corpus Discours US' : 72 documents, 10 auteurs\n",
      "Nombre total de phrases cr√©√©es : 72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def decouper_en_phrases(texte):\n",
    "    \"\"\"D√©coupe un texte en phrases.\"\"\"\n",
    "    phrases = re.split(r'[.!?]+', texte)\n",
    "    phrases = [p.strip() for p in phrases if p.strip() and len(p.strip()) > 20]\n",
    "    return phrases\n",
    "\n",
    "# Cr√©ation du corpus\n",
    "corpus_discours = Corpus(\"Corpus Discours US\")\n",
    "\n",
    "print(\"Cr√©ation du corpus avec d√©coupage en phrases...\")\n",
    "phrase_count = 0\n",
    "\n",
    "for idx, row in tqdm(df_discours.iterrows(), total=len(df_discours), desc=\"Traitement\"):\n",
    "    texte = str(row['texte'])\n",
    "    phrases = decouper_en_phrases(texte)\n",
    "    \n",
    "    for i, phrase in enumerate(phrases):\n",
    "        titre_phrase = f\"{row['titre']} - Phrase {i+1}\"\n",
    "        \n",
    "        doc = DocumentFactory.create_document(\n",
    "            doc_type=row.get('type', 'document').lower(),\n",
    "            titre=titre_phrase,\n",
    "            auteur=row['auteur'],\n",
    "            date=row['date'],\n",
    "            url=row.get('url', ''),\n",
    "            texte=phrase\n",
    "        )\n",
    "        \n",
    "        corpus_discours.add(doc)\n",
    "        phrase_count += 1\n",
    "\n",
    "print(f\"\\n{corpus_discours}\")\n",
    "print(f\"Nombre total de phrases cr√©√©es : {phrase_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 - Test des fonctions search et concorde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TEST DE LA FONCTION SEARCH\n",
      "================================================================================\n",
      "\n",
      "Passages contenant 'learning' : 36\n",
      "\n",
      "Affichage des 5 premiers :\n",
      "\n",
      "1. ...I switched to Machine Learning and I am LOST Hello everybody, I'm a bit lost and...\n",
      "\n",
      "2. ... called AI, which focuses on AI logic and Machine Learning I found this really exciting, so even after learn...\n",
      "\n",
      "3. ... start my journey Best resources to learn Machine Learning deeply in 2‚Äì3 months Hey everyone,  I‚Äôm planning ...\n",
      "\n",
      "4. ...pend the next 2‚Äì3 months fully focused on Machine Learning I already know Python, NumPy, Pandas, Matplotlib,...\n",
      "\n",
      "5. ...ly part I really want to dive into now is Machine Learning itself What I‚Äôm looking for are resources that go...\n"
     ]
    }
   ],
   "source": [
    "# Test de la fonction search\n",
    "print(\"=\"*80)\n",
    "print(\"TEST DE LA FONCTION SEARCH\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "mot_recherche = \"learning\"\n",
    "passages = corpus_discours.search(mot_recherche)\n",
    "\n",
    "print(f\"\\nPassages contenant '{mot_recherche}' : {len(passages)}\")\n",
    "print(f\"\\nAffichage des 5 premiers :\")\n",
    "for i, passage in enumerate(passages[:5], 1):\n",
    "    print(f\"\\n{i}. ...{passage}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TEST DE LA FONCTION CONCORDE\n",
      "================================================================================\n",
      "\n",
      "Occurrences de 'machine' : 24\n",
      "\n",
      "Affichage des 10 premi√®res :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contexte gauche</th>\n",
       "      <th>motif trouv√©</th>\n",
       "      <th>contexte droit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I switched to</td>\n",
       "      <td>Machine</td>\n",
       "      <td>Learning and I am LOST Hello everybody,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alled AI, which focuses on AI logic and</td>\n",
       "      <td>Machine</td>\n",
       "      <td>Learning I found this really exciting,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tart my journey Best resources to learn</td>\n",
       "      <td>Machine</td>\n",
       "      <td>Learning deeply in 2‚Äì3 months Hey every</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nd the next 2‚Äì3 months fully focused on</td>\n",
       "      <td>Machine</td>\n",
       "      <td>Learning I already know Python, NumPy,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>part I really want to dive into now is</td>\n",
       "      <td>Machine</td>\n",
       "      <td>Learning itself What I‚Äôm looking for ar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>on, what resources would you rely on Is</td>\n",
       "      <td>machine</td>\n",
       "      <td>learning a good career in 2025 I hate \"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>my\" \"field\" (</td>\n",
       "      <td>machine</td>\n",
       "      <td>learning) A lot of people (like me) div</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>it works, and yet they act like they do</td>\n",
       "      <td>Machine</td>\n",
       "      <td>Learning Hiring üí™ Data science has beco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>reliability of the data sources and the</td>\n",
       "      <td>machine</td>\n",
       "      <td>learning techniques that support them I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>re crucial to address in the context of</td>\n",
       "      <td>machine</td>\n",
       "      <td>learning for official statistics This p</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            contexte gauche motif trouv√©  \\\n",
       "0                            I switched to       Machine   \n",
       "1  alled AI, which focuses on AI logic and       Machine   \n",
       "2  tart my journey Best resources to learn       Machine   \n",
       "3  nd the next 2‚Äì3 months fully focused on       Machine   \n",
       "4   part I really want to dive into now is       Machine   \n",
       "5  on, what resources would you rely on Is       machine   \n",
       "6                             my\" \"field\" (      machine   \n",
       "7  it works, and yet they act like they do       Machine   \n",
       "8  reliability of the data sources and the       machine   \n",
       "9  re crucial to address in the context of       machine   \n",
       "\n",
       "                             contexte droit  \n",
       "0   Learning and I am LOST Hello everybody,  \n",
       "1   Learning I found this really exciting,   \n",
       "2   Learning deeply in 2‚Äì3 months Hey every  \n",
       "3   Learning I already know Python, NumPy,   \n",
       "4   Learning itself What I‚Äôm looking for ar  \n",
       "5   learning a good career in 2025 I hate \"  \n",
       "6   learning) A lot of people (like me) div  \n",
       "7   Learning Hiring üí™ Data science has beco  \n",
       "8   learning techniques that support them I  \n",
       "9   learning for official statistics This p  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test de la fonction concorde\n",
    "print(\"=\"*80)\n",
    "print(\"TEST DE LA FONCTION CONCORDE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "expression = \"machine\"\n",
    "df_concorde = corpus_discours.concorde(expression, taille_contexte=40)\n",
    "\n",
    "print(f\"\\nOccurrences de '{expression}' : {len(df_concorde)}\")\n",
    "print(f\"\\nAffichage des 10 premi√®res :\")\n",
    "display(df_concorde.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Partie 2 : Utilisation du moteur de recherche\n",
    "## 2.1 - Import et initialisation du SearchEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialisation du moteur de recherche...\n",
      "\n",
      "Moteur initialis√© avec succ√®s !\n",
      "\n",
      "Statistiques du vocabulaire :\n",
      "Taille du vocabulaire : 610 mots\n",
      "\n",
      "Exemple de mots dans le vocabulaire :\n",
      "  - a : 35 occurrences, 25 documents\n",
      "  - ability : 1 occurrences, 1 documents\n",
      "  - about : 2 occurrences, 2 documents\n",
      "  - accuracy : 2 occurrences, 2 documents\n",
      "  - acquisition : 1 occurrences, 1 documents\n",
      "  - act : 1 occurrences, 1 documents\n",
      "  - active : 5 occurrences, 5 documents\n",
      "  - actually : 1 occurrences, 1 documents\n",
      "  - address : 2 occurrences, 2 documents\n",
      "  - adopted : 1 occurrences, 1 documents\n"
     ]
    }
   ],
   "source": [
    "# Initialisation du moteur de recherche\n",
    "print(\"Initialisation du moteur de recherche...\\n\")\n",
    "\n",
    "moteur = SearchEngine(corpus_discours)\n",
    "\n",
    "print(\"Moteur initialis√© avec succ√®s !\")\n",
    "print(\"\\nStatistiques du vocabulaire :\")\n",
    "moteur.afficher_stats_vocab()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 - Test avec plusieurs requ√™tes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Requ√™te : 'machine learning'\n",
      "================================================================================\n",
      "\n",
      "5 r√©sultats trouv√©s :\n",
      "\n",
      "1. [Reddit] Machine Learning Hiring üí™ - Phrase 1\n",
      "   Auteur: Zealousideal_Bit_177\n",
      "   Score: 0.2963\n",
      "\n",
      "2. [Reddit] Is machine learning a good career in 2025? - Phrase 1\n",
      "   Auteur: stanley_john\n",
      "   Score: 0.2094\n",
      "\n",
      "3. [Reddit] Best resources to learn Machine Learning deeply in 2‚Äì3 months? - Phrase 1\n",
      "   Auteur: vansh596\n",
      "   Score: 0.1608\n",
      "\n",
      "4. [Arxiv] Learning Curves for Decision Making in Supervised Machine Learning: A Survey - Phrase 1\n",
      "   Auteur: Felix Mohr\n",
      "   Score: 0.1604\n",
      "\n",
      "5. [Arxiv] Active learning for data streams: a survey - Phrase 1\n",
      "   Auteur: Davide Cacciarelli\n",
      "   Score: 0.1487\n",
      "\n",
      "================================================================================\n",
      "Requ√™te : 'neural network'\n",
      "================================================================================\n",
      "\n",
      "2 r√©sultats trouv√©s :\n",
      "\n",
      "1. [Reddit] Best resources to learn Machine Learning deeply in 2‚Äì3 months? - Phrase 6\n",
      "   Auteur: vansh596\n",
      "   Score: 0.1898\n",
      "\n",
      "2. [Reddit] I switched to Machine Learning and I am LOST - Phrase 4\n",
      "   Auteur: Hertz314159\n",
      "   Score: 0.1788\n",
      "\n",
      "================================================================================\n",
      "Requ√™te : 'data science'\n",
      "================================================================================\n",
      "\n",
      "5 r√©sultats trouv√©s :\n",
      "\n",
      "1. [Arxiv] Changing Data Sources in the Age of Machine Learning for Official Statistics - Phrase 3\n",
      "   Auteur: Cedric De Boom\n",
      "   Score: 0.2851\n",
      "\n",
      "2. [Reddit] I switched to Machine Learning and I am LOST - Phrase 2\n",
      "   Auteur: Hertz314159\n",
      "   Score: 0.2540\n",
      "\n",
      "3. [Arxiv] Changing Data Sources in the Age of Machine Learning for Official Statistics - Phrase 1\n",
      "   Auteur: Cedric De Boom\n",
      "   Score: 0.2527\n",
      "\n",
      "4. [Arxiv] Changing Data Sources in the Age of Machine Learning for Official Statistics - Phrase 2\n",
      "   Auteur: Cedric De Boom\n",
      "   Score: 0.2011\n",
      "\n",
      "5. [Arxiv] Active learning for data streams: a survey - Phrase 1\n",
      "   Auteur: Davide Cacciarelli\n",
      "   Score: 0.1490\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test avec diff√©rentes requ√™tes\n",
    "requetes_test = [\n",
    "    \"machine learning\",\n",
    "    \"neural network\",\n",
    "    \"data science\"\n",
    "]\n",
    "\n",
    "for requete in requetes_test:\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Requ√™te : '{requete}'\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    resultats = moteur.search(requete, nb_resultats=5)\n",
    "    \n",
    "    if len(resultats) > 0:\n",
    "        print(f\"\\n{len(resultats)} r√©sultats trouv√©s :\\n\")\n",
    "        for idx, row in resultats.iterrows():\n",
    "            print(f\"{idx+1}. [{row['type']}] {row['titre']}\")\n",
    "            print(f\"   Auteur: {row['auteur']}\")\n",
    "            print(f\"   Score: {row['score']:.4f}\\n\")\n",
    "    else:\n",
    "        print(\"Aucun r√©sultat trouv√©.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 - Ajout compteur avec tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test avec barre de progression :\n",
      "\n",
      "Traitement de la requ√™te...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R√©cup√©ration: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 3366.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 r√©sultats :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titre</th>\n",
       "      <th>auteur</th>\n",
       "      <th>score</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Machine Learning Hiring üí™ - Phrase 1</td>\n",
       "      <td>Zealousideal_Bit_177</td>\n",
       "      <td>0.296280</td>\n",
       "      <td>Reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Is machine learning a good career in 2025? - P...</td>\n",
       "      <td>stanley_john</td>\n",
       "      <td>0.209361</td>\n",
       "      <td>Reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Best resources to learn Machine Learning deepl...</td>\n",
       "      <td>vansh596</td>\n",
       "      <td>0.160751</td>\n",
       "      <td>Reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Learning Curves for Decision Making in Supervi...</td>\n",
       "      <td>Felix Mohr</td>\n",
       "      <td>0.160388</td>\n",
       "      <td>Arxiv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Active learning for data streams: a survey - P...</td>\n",
       "      <td>Davide Cacciarelli</td>\n",
       "      <td>0.148683</td>\n",
       "      <td>Arxiv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Physics-Inspired Interpretability Of Machine L...</td>\n",
       "      <td>Maximilian P Niroomand</td>\n",
       "      <td>0.145859</td>\n",
       "      <td>Arxiv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Learning Curves for Decision Making in Supervi...</td>\n",
       "      <td>Felix Mohr</td>\n",
       "      <td>0.131296</td>\n",
       "      <td>Arxiv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Best resources to learn Machine Learning deepl...</td>\n",
       "      <td>vansh596</td>\n",
       "      <td>0.120007</td>\n",
       "      <td>Reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Active learning for data streams: a survey - P...</td>\n",
       "      <td>Davide Cacciarelli</td>\n",
       "      <td>0.118852</td>\n",
       "      <td>Arxiv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DOME: Recommendations for supervised machine l...</td>\n",
       "      <td>Ian Walsh</td>\n",
       "      <td>0.118720</td>\n",
       "      <td>Arxiv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               titre                  auteur  \\\n",
       "0               Machine Learning Hiring üí™ - Phrase 1    Zealousideal_Bit_177   \n",
       "1  Is machine learning a good career in 2025? - P...            stanley_john   \n",
       "2  Best resources to learn Machine Learning deepl...                vansh596   \n",
       "3  Learning Curves for Decision Making in Supervi...              Felix Mohr   \n",
       "4  Active learning for data streams: a survey - P...      Davide Cacciarelli   \n",
       "5  Physics-Inspired Interpretability Of Machine L...  Maximilian P Niroomand   \n",
       "6  Learning Curves for Decision Making in Supervi...              Felix Mohr   \n",
       "7  Best resources to learn Machine Learning deepl...                vansh596   \n",
       "8  Active learning for data streams: a survey - P...      Davide Cacciarelli   \n",
       "9  DOME: Recommendations for supervised machine l...               Ian Walsh   \n",
       "\n",
       "      score    type  \n",
       "0  0.296280  Reddit  \n",
       "1  0.209361  Reddit  \n",
       "2  0.160751  Reddit  \n",
       "3  0.160388   Arxiv  \n",
       "4  0.148683   Arxiv  \n",
       "5  0.145859   Arxiv  \n",
       "6  0.131296   Arxiv  \n",
       "7  0.120007  Reddit  \n",
       "8  0.118852   Arxiv  \n",
       "9  0.118720   Arxiv  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Version avec barre de progression\n",
    "def search_with_progress(self, mots_clefs, nb_resultats=10):\n",
    "    print(\"Traitement de la requ√™te...\")\n",
    "    \n",
    "    vecteur_requete = self._vectoriser_requete(mots_clefs)\n",
    "    scores = self._similarite_cosinus(vecteur_requete, self.mat_TFxIDF)\n",
    "    indices_tries = np.argsort(scores)[::-1][:nb_resultats]\n",
    "    \n",
    "    resultats = []\n",
    "    for idx in tqdm(indices_tries, desc=\"R√©cup√©ration\"):\n",
    "        if scores[idx] > 0:\n",
    "            doc = self.corpus.id2doc[idx]\n",
    "            resultats.append({\n",
    "                'doc_id': idx,\n",
    "                'titre': doc.titre,\n",
    "                'auteur': doc.auteur,\n",
    "                'date': doc.date,\n",
    "                'url': doc.url,\n",
    "                'score': scores[idx],\n",
    "                'type': doc.getType()\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(resultats)\n",
    "\n",
    "import types\n",
    "moteur.search_with_progress = types.MethodType(search_with_progress, moteur)\n",
    "\n",
    "# Test\n",
    "print(\"Test avec barre de progression :\\n\")\n",
    "resultats = moteur.search_with_progress(\"machine learning\", nb_resultats=10)\n",
    "\n",
    "if len(resultats) > 0:\n",
    "    print(f\"\\n{len(resultats)} r√©sultats :\")\n",
    "    display(resultats[['titre', 'auteur', 'score', 'type']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Partie 3 : Interface graphique\n",
    "## 3.1 - Cr√©ation des objets graphiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Widgets cr√©√©s !\n"
     ]
    }
   ],
   "source": [
    "# Widgets de base\n",
    "titre_label = widgets.Label(\n",
    "    value='Moteur de recherche'\n",
    ")\n",
    "\n",
    "mots_cles_text = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='mot1 mot2 mot3',\n",
    "    description='Mots cl√©s :',\n",
    "    layout=widgets.Layout(width='500px')\n",
    ")\n",
    "\n",
    "nb_docs_slider = widgets.IntSlider(\n",
    "    value=10,\n",
    "    min=1,\n",
    "    max=50,\n",
    "    description=\"Nombre d'articles √† extraire :\",\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='500px')\n",
    ")\n",
    "\n",
    "print(\"Widgets cr√©√©s !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 - Affichage avec VBox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e235692ad1c411dbc461d906acdf7d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Moteur de recherche'), Text(value='', description='Mots cl√©s :', layout=Layout(wid‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interface_simple = widgets.VBox([\n",
    "    titre_label,\n",
    "    mots_cles_text,\n",
    "    nb_docs_slider\n",
    "])\n",
    "\n",
    "display(interface_simple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 - Ajout de l'objet Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2163f0a45ca14673b3c8880952796715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Moteur de recherche'), Text(value='', description='Mots cl√©s :', layout=Layout(wid‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sortie_resultats = widgets.Output()\n",
    "\n",
    "interface_output = widgets.VBox([\n",
    "    titre_label,\n",
    "    mots_cles_text,\n",
    "    nb_docs_slider,\n",
    "    sortie_resultats\n",
    "])\n",
    "\n",
    "display(interface_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 - Ajout du bouton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cdfb043fc05430fbb4cc45bbf55afb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Moteur de recherche'), Text(value='', description='Mots cl√©s :', layout=Layout(wid‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bouton_recherche = widgets.Button(\n",
    "    description='Rechercher',\n",
    "    button_style='primary',\n",
    "    tooltip='Lancer la recherche',\n",
    "    icon='search'\n",
    ")\n",
    "\n",
    "interface_bouton = widgets.VBox([\n",
    "    titre_label,\n",
    "    mots_cles_text,\n",
    "    nb_docs_slider,\n",
    "    bouton_recherche,\n",
    "    sortie_resultats\n",
    "])\n",
    "\n",
    "display(interface_bouton)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 - Fonction clique_bouton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fonction configur√©e !\n"
     ]
    }
   ],
   "source": [
    "def clique_bouton(b):\n",
    "    requete = mots_cles_text.value\n",
    "    nb_resultats = nb_docs_slider.value\n",
    "    \n",
    "    sortie_resultats.clear_output()\n",
    "    \n",
    "    with sortie_resultats:\n",
    "        if not requete.strip():\n",
    "            print(\" Veuillez entrer des mots cl√©s.\")\n",
    "            return\n",
    "        \n",
    "        print(f\" Recherche : '{requete}'\")\n",
    "        print(f\" Nombre de r√©sultats : {nb_resultats}\")\n",
    "        print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "        \n",
    "        try:\n",
    "            resultats = moteur.search(requete, nb_resultats=nb_resultats)\n",
    "            \n",
    "            if len(resultats) > 0:\n",
    "                print(f\" {len(resultats)} r√©sultats trouv√©s :\\n\")\n",
    "                \n",
    "                for idx, row in resultats.iterrows():\n",
    "                    print(f\"  R√©sultat {idx+1}\")\n",
    "                    print(f\"   Type: [{row['type']}]\")\n",
    "                    print(f\"   Titre: {row['titre']}\")\n",
    "                    print(f\"   Auteur: {row['auteur']}\")\n",
    "                    print(f\"   Score: {row['score']:.4f}\")\n",
    "                    print(f\"   URL: {row['url']}\")\n",
    "                    print(\"\\n\" + \"-\"*80 + \"\\n\")\n",
    "                \n",
    "                print(\"\\n Tableau r√©capitulatif :\\n\")\n",
    "                display(resultats[['titre', 'auteur', 'score', 'type']])\n",
    "                \n",
    "            else:\n",
    "                print(\" Aucun r√©sultat trouv√©.\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\" Erreur : {str(e)}\")\n",
    "\n",
    "bouton_recherche.on_click(clique_bouton)\n",
    "print(\"Fonction configur√©e !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 - Interface compl√®te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interface de recherche compl√®te :\n",
      "Entrez vos mots cl√©s et cliquez sur 'Rechercher'\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0b057e4e3a34232b85bf1ef7767f979",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Moteur de recherche'), HTML(value='<hr>'), Text(value='', description='Mots cl√©s :‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Interface de recherche compl√®te :\")\n",
    "print(\"Entrez vos mots cl√©s et cliquez sur 'Rechercher'\\n\")\n",
    "\n",
    "interface_complete = widgets.VBox([\n",
    "    titre_label,\n",
    "    widgets.HTML(value=\"<hr>\"),\n",
    "    mots_cles_text,\n",
    "    nb_docs_slider,\n",
    "    bouton_recherche,\n",
    "    widgets.HTML(value=\"<hr>\"),\n",
    "    sortie_resultats\n",
    "], layout=widgets.Layout(padding='10px', border='2px solid #ccc'))\n",
    "\n",
    "display(interface_complete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7 - Interface avanc√©e avec filtres "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interface avanc√©e avec filtres :\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "288d085038574dcc82a3ed5f4b91bf13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Moteur de recherche avanc√©'), HTML(value='<hr>'), Text(value='', description='Mots‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Interface avanc√©e avec filtres\n",
    "auteurs_uniques = ['Tous'] + sorted(list(set([doc.auteur for doc in corpus_discours.id2doc.values()])))\n",
    "\n",
    "titre_avance = widgets.Label(value='Moteur de recherche avanc√©')\n",
    "\n",
    "filtre_auteur = widgets.Dropdown(\n",
    "    options=auteurs_uniques,\n",
    "    value='Tous',\n",
    "    description='Auteur :'\n",
    ")\n",
    "\n",
    "filtre_type = widgets.Dropdown(\n",
    "    options=['Tous', 'Reddit', 'Arxiv', 'Document'],\n",
    "    value='Tous',\n",
    "    description='Type :'\n",
    ")\n",
    "\n",
    "mots_cles_avance = widgets.Text(\n",
    "    placeholder='mot1 mot2 mot3',\n",
    "    description='Mots cl√©s :',\n",
    "    layout=widgets.Layout(width='500px')\n",
    ")\n",
    "\n",
    "nb_docs_avance = widgets.IntSlider(\n",
    "    value=10,\n",
    "    min=1,\n",
    "    max=50,\n",
    "    description=\"Nombre :\",\n",
    "    layout=widgets.Layout(width='500px')\n",
    ")\n",
    "\n",
    "bouton_avance = widgets.Button(\n",
    "    description='Rechercher',\n",
    "    button_style='success',\n",
    "    icon='search'\n",
    ")\n",
    "\n",
    "sortie_avance = widgets.Output()\n",
    "\n",
    "def recherche_avancee(b):\n",
    "    requete = mots_cles_avance.value\n",
    "    nb_resultats = nb_docs_avance.value\n",
    "    auteur_filtre = filtre_auteur.value\n",
    "    type_filtre = filtre_type.value\n",
    "    \n",
    "    sortie_avance.clear_output()\n",
    "    \n",
    "    with sortie_avance:\n",
    "        if not requete.strip():\n",
    "            print(\" Entrez des mots cl√©s.\")\n",
    "            return\n",
    "        \n",
    "        print(f\"  Recherche avanc√©e\")\n",
    "        print(f\"   Requ√™te : '{requete}'\")\n",
    "        print(f\"   Filtre auteur : {auteur_filtre}\")\n",
    "        print(f\"   Filtre type : {type_filtre}\")\n",
    "        print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "        \n",
    "        try:\n",
    "            resultats = moteur.search(requete, nb_resultats=nb_resultats*3)\n",
    "            \n",
    "            if auteur_filtre != 'Tous':\n",
    "                resultats = resultats[resultats['auteur'] == auteur_filtre]\n",
    "            \n",
    "            if type_filtre != 'Tous':\n",
    "                resultats = resultats[resultats['type'] == type_filtre]\n",
    "            \n",
    "            resultats = resultats.head(nb_resultats)\n",
    "            \n",
    "            if len(resultats) > 0:\n",
    "                print(f\" {len(resultats)} r√©sultats apr√®s filtrage :\\n\")\n",
    "                \n",
    "                for idx, row in resultats.iterrows():\n",
    "                    print(f\"  {idx+1}. [{row['type']}] {row['titre']}\")\n",
    "                    print(f\"   Auteur: {row['auteur']}\")\n",
    "                    print(f\"   Score: {row['score']:.4f}\\n\")\n",
    "                \n",
    "                print(\"\\n Tableau :\")\n",
    "                display(resultats[['titre', 'auteur', 'score', 'type']])\n",
    "            else:\n",
    "                print(\" Aucun r√©sultat.\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\" Erreur : {e}\")\n",
    "\n",
    "bouton_avance.on_click(recherche_avancee)\n",
    "\n",
    "interface_avancee = widgets.VBox([\n",
    "    titre_avance,\n",
    "    widgets.HTML(value=\"<hr>\"),\n",
    "    mots_cles_avance,\n",
    "    widgets.HBox([filtre_auteur, filtre_type]),\n",
    "    nb_docs_avance,\n",
    "    bouton_avance,\n",
    "    widgets.HTML(value=\"<hr>\"),\n",
    "    sortie_avance\n",
    "], layout=widgets.Layout(padding='15px', border='3px solid #4CAF50'))\n",
    "\n",
    "print(\"Interface avanc√©e avec filtres :\")\n",
    "display(interface_avancee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>texte</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-10-29 01:46:28</td>\n",
       "      <td>i switched to machine learning and i am lost h...</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-10-29 01:46:28</td>\n",
       "      <td>i m in a year computer science program</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-10-29 01:46:28</td>\n",
       "      <td>the first years cover general programming and ...</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-10-29 01:46:28</td>\n",
       "      <td>we had two specializations software and networ...</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-10-29 01:46:28</td>\n",
       "      <td>i found this really exciting so even after lea...</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date                                              texte  year\n",
       "0 2025-10-29 01:46:28  i switched to machine learning and i am lost h...  2025\n",
       "1 2025-10-29 01:46:28             i m in a year computer science program  2025\n",
       "2 2025-10-29 01:46:28  the first years cover general programming and ...  2025\n",
       "3 2025-10-29 01:46:28  we had two specializations software and networ...  2025\n",
       "4 2025-10-29 01:46:28  i found this really exciting so even after lea...  2025"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "\n",
    "for doc in corpus_discours.id2doc.values():\n",
    "    if doc.date is not None:\n",
    "        data.append({\n",
    "            \"date\": pd.to_datetime(doc.date),\n",
    "            \"texte\": corpus_discours.nettoyer_texte(doc.texte)\n",
    "        })\n",
    "\n",
    "df_time = pd.DataFrame(data)\n",
    "df_time[\"year\"] = df_time[\"date\"].dt.year\n",
    "\n",
    "df_time.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evolution_mot(df, mot):\n",
    "    mot = mot.lower()\n",
    "    freq_par_annee = defaultdict(int)\n",
    "    total_par_annee = defaultdict(int)\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        mots = row[\"texte\"].split()\n",
    "        annee = row[\"year\"]\n",
    "\n",
    "        total_par_annee[annee] += len(mots)\n",
    "        freq_par_annee[annee] += mots.count(mot)\n",
    "\n",
    "    resultats = []\n",
    "\n",
    "    for annee in sorted(freq_par_annee.keys()):\n",
    "        freq_relative = 0\n",
    "        if total_par_annee[annee] > 0:\n",
    "            freq_relative = freq_par_annee[annee] / total_par_annee[annee]\n",
    "\n",
    "        resultats.append({\n",
    "            \"ann√©e\": annee,\n",
    "            \"fr√©quence\": freq_relative\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(resultats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mot_temps = widgets.Text(\n",
    "    description=\"Mot :\",\n",
    "    placeholder=\"ex: learning\"\n",
    ")\n",
    "\n",
    "bouton_temps = widgets.Button(\n",
    "    description=\"√âvolution temporelle\",\n",
    "    button_style=\"info\"\n",
    ")\n",
    "\n",
    "sortie_temps = widgets.Output()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def afficher_evolution(b):\n",
    "    with sortie_temps:\n",
    "        sortie_temps.clear_output()\n",
    "\n",
    "        mot = mot_temps.value.strip()\n",
    "        if not mot:\n",
    "            print(\"Veuillez entrer un mot.\")\n",
    "            return\n",
    "\n",
    "        df_evol = evolution_mot(df_time, mot)\n",
    "\n",
    "        if df_evol.empty:\n",
    "            print(\"Aucune donn√©e disponible.\")\n",
    "            return\n",
    "\n",
    "        display(df_evol)\n",
    "\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        plt.plot(df_evol[\"ann√©e\"], df_evol[\"fr√©quence\"], marker=\"o\")\n",
    "        plt.title(f\"√âvolution du mot '{mot}' dans le temps\")\n",
    "        plt.xlabel(\"Ann√©e\")\n",
    "        plt.ylabel(\"Fr√©quence relative\")\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "bouton_temps.on_click(afficher_evolution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53e9efbe2088423c8eea7885029b45db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Analyse temporelle du vocabulaire'), Text(value='', description='Mot :', placehold‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interface_temps = widgets.VBox([\n",
    "    widgets.Label(\"Analyse temporelle du vocabulaire\"),\n",
    "    mot_temps,\n",
    "    bouton_temps,\n",
    "    sortie_temps\n",
    "], layout=widgets.Layout(\n",
    "    padding='15px',\n",
    "    border='3px solid #2196F3'\n",
    "))\n",
    "\n",
    "display(interface_temps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Analyse avanc√©e du vocabulaire (TF-IDF et BM25)\n",
    "\n",
    "Cette section impl√©mente les mesures **TF-IDF** et **OKAPI-BM25** pour analyser l'importance des mots dans le corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports suppl√©mentaires pour TF-IDF et BM25\n",
    "import math\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnalyseurVocabulaire:\n",
    "    \"\"\"Classe pour analyser le vocabulaire avec TF-IDF et BM25\"\"\"\n",
    "    \n",
    "    def __init__(self, corpus):\n",
    "        self.corpus = corpus\n",
    "        self.docs = list(corpus.id2doc.values())\n",
    "        self.N = len(self.docs)  # Nombre total de documents\n",
    "        self.avgdl = 0  # Longueur moyenne des documents\n",
    "        self.df = {}  # Document frequency pour chaque mot\n",
    "        self.idf = {}  # IDF pour chaque mot\n",
    "        \n",
    "        self._calculer_stats()\n",
    "    \n",
    "    def _calculer_stats(self):\n",
    "        \"\"\"Calcule les statistiques n√©cessaires (DF, IDF, avgdl)\"\"\"\n",
    "        total_length = 0\n",
    "        doc_freq = Counter()\n",
    "        \n",
    "        for doc in self.docs:\n",
    "            texte_nettoye = self.corpus.nettoyer_texte(doc.texte)\n",
    "            mots = texte_nettoye.split()\n",
    "            total_length += len(mots)\n",
    "            \n",
    "            # Document frequency : nombre de docs contenant chaque mot\n",
    "            mots_uniques = set(mots)\n",
    "            for mot in mots_uniques:\n",
    "                doc_freq[mot] += 1\n",
    "        \n",
    "        self.avgdl = total_length / self.N if self.N > 0 else 0\n",
    "        self.df = doc_freq\n",
    "        \n",
    "        # Calcul de l'IDF\n",
    "        for mot, freq in self.df.items():\n",
    "            self.idf[mot] = math.log((self.N - freq + 0.5) / (freq + 0.5) + 1)\n",
    "    \n",
    "    def calculer_tf(self, texte):\n",
    "        \"\"\"Calcule la fr√©quence des termes (TF) dans un texte\"\"\"\n",
    "        mots = self.corpus.nettoyer_texte(texte).split()\n",
    "        tf = Counter(mots)\n",
    "        total_mots = len(mots)\n",
    "        \n",
    "        # Normalisation par la longueur du document\n",
    "        for mot in tf:\n",
    "            tf[mot] = tf[mot] / total_mots if total_mots > 0 else 0\n",
    "        \n",
    "        return tf\n",
    "    \n",
    "    def calculer_tfidf(self, texte):\n",
    "        \"\"\"Calcule TF-IDF pour un texte\"\"\"\n",
    "        tf = self.calculer_tf(texte)\n",
    "        tfidf = {}\n",
    "        \n",
    "        for mot, tf_value in tf.items():\n",
    "            idf_value = self.idf.get(mot, 0)\n",
    "            tfidf[mot] = tf_value * idf_value\n",
    "        \n",
    "        return tfidf\n",
    "    \n",
    "    def calculer_bm25(self, texte, k1=1.5, b=0.75):\n",
    "        \"\"\"\n",
    "        Calcule le score BM25 pour un texte\n",
    "        k1 : param√®tre de saturation du terme (typiquement entre 1.2 et 2.0)\n",
    "        b : param√®tre de normalisation de longueur (typiquement 0.75)\n",
    "        \"\"\"\n",
    "        mots = self.corpus.nettoyer_texte(texte).split()\n",
    "        tf = Counter(mots)\n",
    "        dl = len(mots)  # longueur du document\n",
    "        \n",
    "        bm25_scores = {}\n",
    "        \n",
    "        for mot, freq in tf.items():\n",
    "            if mot in self.idf:\n",
    "                # Formule BM25\n",
    "                idf = self.idf[mot]\n",
    "                numerateur = freq * (k1 + 1)\n",
    "                denominateur = freq + k1 * (1 - b + b * (dl / self.avgdl))\n",
    "                bm25_scores[mot] = idf * (numerateur / denominateur)\n",
    "        \n",
    "        return bm25_scores\n",
    "    \n",
    "    def top_mots_tfidf(self, texte, n=10):\n",
    "        \"\"\"Retourne les n mots avec les scores TF-IDF les plus √©lev√©s\"\"\"\n",
    "        tfidf = self.calculer_tfidf(texte)\n",
    "        return sorted(tfidf.items(), key=lambda x: x[1], reverse=True)[:n]\n",
    "    \n",
    "    def top_mots_bm25(self, texte, n=10):\n",
    "        \"\"\"Retourne les n mots avec les scores BM25 les plus √©lev√©s\"\"\"\n",
    "        bm25 = self.calculer_bm25(texte)\n",
    "        return sorted(bm25.items(), key=lambda x: x[1], reverse=True)[:n]\n",
    "    \n",
    "    def comparer_corpus(self, texte1, texte2, n=20):\n",
    "        \"\"\"\n",
    "        Compare deux textes (ou sous-corpus) et identifie :\n",
    "        - Mots communs\n",
    "        - Mots sp√©cifiques au texte 1\n",
    "        - Mots sp√©cifiques au texte 2\n",
    "        \"\"\"\n",
    "        tfidf1 = self.calculer_tfidf(texte1)\n",
    "        tfidf2 = self.calculer_tfidf(texte2)\n",
    "        \n",
    "        mots1 = set(tfidf1.keys())\n",
    "        mots2 = set(tfidf2.keys())\n",
    "        \n",
    "        # Mots communs\n",
    "        communs = mots1.intersection(mots2)\n",
    "        communs_scores = [(mot, tfidf1[mot], tfidf2[mot]) for mot in communs]\n",
    "        communs_scores.sort(key=lambda x: x[1] + x[2], reverse=True)\n",
    "        \n",
    "        # Mots sp√©cifiques\n",
    "        specifiques1 = [(mot, tfidf1[mot]) for mot in mots1 - mots2]\n",
    "        specifiques1.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        specifiques2 = [(mot, tfidf2[mot]) for mot in mots2 - mots1]\n",
    "        specifiques2.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        return {\n",
    "            'communs': communs_scores[:n],\n",
    "            'specifiques_1': specifiques1[:n],\n",
    "            'specifiques_2': specifiques2[:n]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialisation de l'analyseur de vocabulaire...\n",
      "‚úì Analyseur pr√™t ! (N=72 docs, avgdl=20.39 mots)\n"
     ]
    }
   ],
   "source": [
    "# Initialisation de l'analyseur de vocabulaire\n",
    "print(\"Initialisation de l'analyseur de vocabulaire...\")\n",
    "analyseur = AnalyseurVocabulaire(corpus_discours)\n",
    "print(f\"‚úì Analyseur pr√™t ! (N={analyseur.N} docs, avgdl={analyseur.avgdl:.2f} mots)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interface d'analyse TF-IDF/BM25 :\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef42efe5d8c44f55804b37169518c39d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=\"<h3 style='color: #FF5722;'> Analyse TF-IDF et BM25</h3>\"), HTML(value='<hr>'), Tex‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# INTERFACE : Analyse TF-IDF et BM25 d'un document\n",
    "# ============================================================\n",
    "\n",
    "titre_analyse = widgets.HTML(\n",
    "    value=\"<h3 style='color: #FF5722;'> Analyse TF-IDF et BM25</h3>\"\n",
    ")\n",
    "\n",
    "texte_analyse = widgets.Textarea(\n",
    "    placeholder=\"Collez un texte √† analyser ici...\",\n",
    "    description=\"Texte :\",\n",
    "    layout=widgets.Layout(width='100%', height='150px')\n",
    ")\n",
    "\n",
    "nb_mots_top = widgets.IntSlider(\n",
    "    value=10,\n",
    "    min=5,\n",
    "    max=30,\n",
    "    step=5,\n",
    "    description=\"Top mots :\",\n",
    "    style={'description_width': '100px'}\n",
    ")\n",
    "\n",
    "bouton_analyse = widgets.Button(\n",
    "    description=\"Analyser\",\n",
    "    button_style=\"warning\",\n",
    "    icon='search'\n",
    ")\n",
    "\n",
    "sortie_analyse = widgets.Output()\n",
    "\n",
    "def analyser_document(b):\n",
    "    with sortie_analyse:\n",
    "        sortie_analyse.clear_output()\n",
    "        \n",
    "        texte = texte_analyse.value.strip()\n",
    "        if not texte:\n",
    "            print(\" Veuillez entrer un texte √† analyser.\")\n",
    "            return\n",
    "        \n",
    "        n = nb_mots_top.value\n",
    "        \n",
    "        print(\" Analyse en cours...\\n\")\n",
    "        \n",
    "        # TF-IDF\n",
    "        print(\"=\" * 60)\n",
    "        print(\" TOP MOTS PAR TF-IDF\")\n",
    "        print(\"=\" * 60)\n",
    "        top_tfidf = analyseur.top_mots_tfidf(texte, n)\n",
    "        for i, (mot, score) in enumerate(top_tfidf, 1):\n",
    "            print(f\"{i:2d}. {mot:20s} ‚Üí {score:.4f}\")\n",
    "        \n",
    "        # BM25\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\" TOP MOTS PAR BM25\")\n",
    "        print(\"=\" * 60)\n",
    "        top_bm25 = analyseur.top_mots_bm25(texte, n)\n",
    "        for i, (mot, score) in enumerate(top_bm25, 1):\n",
    "            print(f\"{i:2d}. {mot:20s} ‚Üí {score:.4f}\")\n",
    "        \n",
    "        # Statistiques\n",
    "        mots = corpus_discours.nettoyer_texte(texte).split()\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\" STATISTIQUES\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"Nombre de mots : {len(mots)}\")\n",
    "        print(f\"Mots uniques : {len(set(mots))}\")\n",
    "        print(f\"Longueur moyenne corpus : {analyseur.avgdl:.2f} mots\")\n",
    "\n",
    "bouton_analyse.on_click(analyser_document)\n",
    "\n",
    "interface_analyse = widgets.VBox([\n",
    "    titre_analyse,\n",
    "    widgets.HTML(value=\"<hr>\"),\n",
    "    texte_analyse,\n",
    "    nb_mots_top,\n",
    "    bouton_analyse,\n",
    "    widgets.HTML(value=\"<hr>\"),\n",
    "    sortie_analyse\n",
    "], layout=widgets.Layout(padding='15px', border='3px solid #FF5722'))\n",
    "\n",
    "print(\"Interface d'analyse TF-IDF/BM25 :\")\n",
    "display(interface_analyse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interface de comparaison de corpus :\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83434f5c2831484d92f3aba58b4ee68c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=\"<h3 style='color: #9C27B0;'>Comparaison de deux corpus</h3>\"), HTML(value='<hr>'), ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# INTERFACE : Comparaison de deux corpus\n",
    "# ============================================================\n",
    "\n",
    "titre_comparaison = widgets.HTML(\n",
    "    value=\"<h3 style='color: #9C27B0;'>Comparaison de deux corpus</h3>\"\n",
    ")\n",
    "\n",
    "# S√©lection du crit√®re de division\n",
    "critere_division = widgets.Dropdown(\n",
    "    options=['auteur', 'type'],\n",
    "    value='type',\n",
    "    description=\"Diviser par :\",\n",
    "    style={'description_width': '100px'}\n",
    ")\n",
    "\n",
    "# Widgets pour s√©lectionner les deux groupes √† comparer\n",
    "groupe1_select = widgets.Dropdown(\n",
    "    description=\"Groupe 1 :\",\n",
    "    style={'description_width': '100px'}\n",
    ")\n",
    "\n",
    "groupe2_select = widgets.Dropdown(\n",
    "    description=\"Groupe 2 :\",\n",
    "    style={'description_width': '100px'}\n",
    ")\n",
    "\n",
    "nb_mots_comparaison = widgets.IntSlider(\n",
    "    value=15,\n",
    "    min=5,\n",
    "    max=30,\n",
    "    step=5,\n",
    "    description=\"Top mots :\",\n",
    "    style={'description_width': '100px'}\n",
    ")\n",
    "\n",
    "bouton_comparer = widgets.Button(\n",
    "    description=\"Comparer\",\n",
    "    button_style=\"success\"\n",
    ")\n",
    "\n",
    "sortie_comparaison = widgets.Output()\n",
    "\n",
    "def mettre_a_jour_groupes(change):\n",
    "    \"\"\"Met √† jour les options des dropdowns selon le crit√®re\"\"\"\n",
    "    critere = critere_division.value\n",
    "    \n",
    "    if critere == 'auteur':\n",
    "        auteurs = set()\n",
    "        for doc in corpus_discours.id2doc.values():\n",
    "            if doc.auteur:\n",
    "                auteurs.add(doc.auteur)\n",
    "        options = sorted(list(auteurs))\n",
    "    elif critere == 'type':\n",
    "        types = set()\n",
    "        for doc in corpus_discours.id2doc.values():\n",
    "            if hasattr(doc, 'type') and doc.type:\n",
    "                types.add(doc.type)\n",
    "        options = sorted(list(types))\n",
    "    else:\n",
    "        options = []\n",
    "    \n",
    "    groupe1_select.options = options\n",
    "    groupe2_select.options = options\n",
    "    if len(options) >= 2:\n",
    "        groupe1_select.value = options[0]\n",
    "        groupe2_select.value = options[1] if len(options) > 1 else options[0]\n",
    "\n",
    "# Initialiser les options\n",
    "mettre_a_jour_groupes(None)\n",
    "critere_division.observe(mettre_a_jour_groupes, names='value')\n",
    "\n",
    "def comparer_groupes(b):\n",
    "    with sortie_comparaison:\n",
    "        sortie_comparaison.clear_output()\n",
    "        \n",
    "        critere = critere_division.value\n",
    "        groupe1 = groupe1_select.value\n",
    "        groupe2 = groupe2_select.value\n",
    "        n = nb_mots_comparaison.value\n",
    "        \n",
    "        if not groupe1 or not groupe2:\n",
    "            print(\"Veuillez s√©lectionner deux groupes.\")\n",
    "            return\n",
    "        \n",
    "        if groupe1 == groupe2:\n",
    "            print(\"Veuillez s√©lectionner deux groupes diff√©rents.\")\n",
    "            return\n",
    "        \n",
    "        print(f\"Comparaison : {groupe1} vs {groupe2}\\n\")\n",
    "        \n",
    "        # Cr√©er deux textes √† partir des documents\n",
    "        texte1_parts = []\n",
    "        texte2_parts = []\n",
    "        \n",
    "        for doc in corpus_discours.id2doc.values():\n",
    "            if critere == 'auteur' and doc.auteur == groupe1:\n",
    "                texte1_parts.append(doc.texte)\n",
    "            elif critere == 'auteur' and doc.auteur == groupe2:\n",
    "                texte2_parts.append(doc.texte)\n",
    "            elif critere == 'type' and hasattr(doc, 'type') and doc.type == groupe1:\n",
    "                texte1_parts.append(doc.texte)\n",
    "            elif critere == 'type' and hasattr(doc, 'type') and doc.type == groupe2:\n",
    "                texte2_parts.append(doc.texte)\n",
    "        \n",
    "        texte1 = \" \".join(texte1_parts)\n",
    "        texte2 = \" \".join(texte2_parts)\n",
    "        \n",
    "        if not texte1 or not texte2:\n",
    "            print(\"Un des groupes ne contient aucun document.\")\n",
    "            return\n",
    "        \n",
    "        # Comparaison\n",
    "        resultats = analyseur.comparer_corpus(texte1, texte2, n)\n",
    "        \n",
    "        # Affichage des r√©sultats\n",
    "        print(\"=\" * 70)\n",
    "        print(f\"MOTS SP√âCIFIQUES √Ä : {groupe1}\")\n",
    "        print(\"=\" * 70)\n",
    "        for i, (mot, score) in enumerate(resultats['specifiques_1'], 1):\n",
    "            print(f\"{i:2d}. {mot:25s} ‚Üí TF-IDF: {score:.4f}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(f\"MOTS SP√âCIFIQUES √Ä : {groupe2}\")\n",
    "        print(\"=\" * 70)\n",
    "        for i, (mot, score) in enumerate(resultats['specifiques_2'], 1):\n",
    "            print(f\"{i:2d}. {mot:25s} ‚Üí TF-IDF: {score:.4f}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"MOTS COMMUNS (scores combin√©s)\")\n",
    "        print(\"=\" * 70)\n",
    "        for i, (mot, score1, score2) in enumerate(resultats['communs'], 1):\n",
    "            total = score1 + score2\n",
    "            print(f\"{i:2d}. {mot:25s} ‚Üí {groupe1}: {score1:.4f} | {groupe2}: {score2:.4f}\")\n",
    "        \n",
    "        # Statistiques\n",
    "        mots1 = corpus_discours.nettoyer_texte(texte1).split()\n",
    "        mots2 = corpus_discours.nettoyer_texte(texte2).split()\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"STATISTIQUES\")\n",
    "        print(\"=\" * 70)\n",
    "        print(f\"{groupe1:25s} ‚Üí {len(texte1_parts)} docs, {len(mots1)} mots, {len(set(mots1))} mots uniques\")\n",
    "        print(f\"{groupe2:25s} ‚Üí {len(texte2_parts)} docs, {len(mots2)} mots, {len(set(mots2))} mots uniques\")\n",
    "\n",
    "bouton_comparer.on_click(comparer_groupes)\n",
    "\n",
    "interface_comparaison = widgets.VBox([\n",
    "    titre_comparaison,\n",
    "    widgets.HTML(value=\"<hr>\"),\n",
    "    critere_division,\n",
    "    widgets.HBox([groupe1_select, groupe2_select]),\n",
    "    nb_mots_comparaison,\n",
    "    bouton_comparer,\n",
    "    widgets.HTML(value=\"<hr>\"),\n",
    "    sortie_comparaison\n",
    "], layout=widgets.Layout(padding='15px', border='3px solid #9C27B0'))\n",
    "\n",
    "print(\"Interface de comparaison de corpus :\")\n",
    "display(interface_comparaison)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fcc86bdb19e4d4f9b1ea928efa042ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Button(button_style='info', description=' Visualiser les scores', style=ButtonStyle()), Output(‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# VISUALISATION : Graphiques TF-IDF et BM25\n",
    "# ============================================================\n",
    "\n",
    "def visualiser_scores(texte, n=15):\n",
    "    \"\"\"Cr√©e des graphiques pour comparer TF-IDF et BM25\"\"\"\n",
    "    \n",
    "    top_tfidf = analyseur.top_mots_tfidf(texte, n)\n",
    "    top_bm25 = analyseur.top_mots_bm25(texte, n)\n",
    "    \n",
    "    # Extraction des donn√©es\n",
    "    mots_tfidf = [mot for mot, _ in top_tfidf]\n",
    "    scores_tfidf = [score for _, score in top_tfidf]\n",
    "    \n",
    "    mots_bm25 = [mot for mot, _ in top_bm25]\n",
    "    scores_bm25 = [score for _, score in top_bm25]\n",
    "    \n",
    "    # Cr√©ation des graphiques\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # TF-IDF\n",
    "    ax1.barh(range(len(mots_tfidf)), scores_tfidf, color='#2196F3')\n",
    "    ax1.set_yticks(range(len(mots_tfidf)))\n",
    "    ax1.set_yticklabels(mots_tfidf)\n",
    "    ax1.set_xlabel('Score TF-IDF', fontsize=12)\n",
    "    ax1.set_title('Top mots par TF-IDF', fontsize=14, fontweight='bold')\n",
    "    ax1.invert_yaxis()\n",
    "    ax1.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    # BM25\n",
    "    ax2.barh(range(len(mots_bm25)), scores_bm25, color='#FF5722')\n",
    "    ax2.set_yticks(range(len(mots_bm25)))\n",
    "    ax2.set_yticklabels(mots_bm25)\n",
    "    ax2.set_xlabel('Score BM25', fontsize=12)\n",
    "    ax2.set_title('Top mots par BM25', fontsize=14, fontweight='bold')\n",
    "    ax2.invert_yaxis()\n",
    "    ax2.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Widget pour tester la visualisation\n",
    "bouton_visu = widgets.Button(\n",
    "    description=\" Visualiser les scores\",\n",
    "    button_style=\"info\"\n",
    ")\n",
    "\n",
    "sortie_visu = widgets.Output()\n",
    "\n",
    "def afficher_visualisation(b):\n",
    "    with sortie_visu:\n",
    "        sortie_visu.clear_output()\n",
    "        \n",
    "        texte = texte_analyse.value.strip()\n",
    "        if not texte:\n",
    "            print(\" Veuillez d'abord entrer un texte dans l'interface d'analyse ci-dessus.\")\n",
    "            return\n",
    "        \n",
    "        visualiser_scores(texte, nb_mots_top.value)\n",
    "\n",
    "bouton_visu.on_click(afficher_visualisation)\n",
    "\n",
    "display(widgets.VBox([\n",
    "    bouton_visu,\n",
    "    sortie_visu\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
