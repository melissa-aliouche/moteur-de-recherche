{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TD 8–10 : Moteur de recherche avec Jupyter\n",
    "\n",
    "Ce notebook regroupe les TD 8, 9 et 10.\n",
    "\n",
    "- **TD 8** : chargement du corpus, moteur de recherche et interface graphique avec ipywidgets.\n",
    "- **TD 9–10** : ajout de filtres, analyses du vocabulaire et exploration temporelle des mots.\n",
    "\n",
    "L’objectif est de proposer une interface interactive pour explorer et analyser le corpus.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation des dépendances nécessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation des packages nécessaires\n",
    "!pip install pandas numpy scipy ipywidgets tqdm matplotlib seaborn plotly --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports des bibliothèques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import re\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "# Imports de vos classes personnalisées\n",
    "from Corpus import Corpus\n",
    "from Document import Document\n",
    "from DocumentFactory import DocumentFactory\n",
    "from SearchEngine import SearchEngine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Partie 1 : Démarrage\n",
    "## 1.1 - Récupération et chargement du jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aperçu des données :\n",
      "   id                                              titre              auteur  \\\n",
      "0   0       I switched to Machine Learning and I am LOST         Hertz314159   \n",
      "1   1  Best resources to learn Machine Learning deepl...            vansh596   \n",
      "2   2           Is a machine learning career still good?            BBBixncx   \n",
      "3   3                      Getting into Machine Learning   Working_Dress9277   \n",
      "4   4                 How do you learn machine learning?  ShortImplement4486   \n",
      "\n",
      "                  date                                                url  \\\n",
      "0  2025-10-29 01:46:28  https://reddit.com/r/learnmachinelearning/comm...   \n",
      "1  2025-08-18 13:53:27  https://reddit.com/r/learnmachinelearning/comm...   \n",
      "2  2025-10-12 07:37:00  https://reddit.com/r/AskProgramming/comments/1...   \n",
      "3  2025-12-07 18:34:38  https://reddit.com/r/learnmachinelearning/comm...   \n",
      "4  2025-11-18 08:01:41  https://reddit.com/r/computerscience/comments/...   \n",
      "\n",
      "                                               texte    type  \n",
      "0  I switched to Machine Learning and I am LOST H...  Reddit  \n",
      "1  Best resources to learn Machine Learning deepl...  Reddit  \n",
      "2  Is a machine learning career still good? Hi I’...  Reddit  \n",
      "3  Getting into Machine Learning Hello,  I have a...  Reddit  \n",
      "4  How do you learn machine learning? i see two p...  Reddit  \n",
      "\n",
      "Nombre total de documents : 49\n",
      "\n",
      "Colonnes disponibles : ['id', 'titre', 'auteur', 'date', 'url', 'texte', 'type']\n"
     ]
    }
   ],
   "source": [
    "# Chargement du fichier TSV\n",
    "df_discours = pd.read_csv('corpus.tsv', sep='\\t')\n",
    "\n",
    "print(\"Aperçu des données :\")\n",
    "print(df_discours.head())\n",
    "print(f\"\\nNombre total de documents : {len(df_discours)}\")\n",
    "print(f\"\\nColonnes disponibles : {list(df_discours.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 - Vérification de la distribution des auteurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution des auteurs :\n",
      "Morteza Haghir Chehreghani     2\n",
      "Sorin61                        2\n",
      "Sung Whan Yoon                 1\n",
      "Gustavo Correa Publio          1\n",
      "space-_-man                    1\n",
      "Matias Valdenegro-Toro         1\n",
      "maxwellhill                    1\n",
      "Willing-Arugula3238            1\n",
      "Geoffroy Dubourg-Felonneau     1\n",
      "Thomas M. Moerland             1\n",
      "egocentric-video               1\n",
      "Carmen Martin-Turrero          1\n",
      "gaeioran                       1\n",
      "Olga Cherednichenko            1\n",
      "Junaed Younus Khan             1\n",
      "BBBixncx                       1\n",
      "ShortImplement4486             1\n",
      "Cedric De Boom                 1\n",
      "dstori                         1\n",
      "TrapWolf                       1\n",
      "Lun Ai                         1\n",
      "Diego Granziol                 1\n",
      "legehjernen                    1\n",
      "Matthew B. A. McDermott        1\n",
      "Substantial-Art-2238           1\n",
      "Affectionate-Army458           1\n",
      "Felix Mohr                     1\n",
      "esberat                        1\n",
      "Cynthia Rudin                  1\n",
      "Canon_Cowboy                   1\n",
      "vansh596                       1\n",
      "loved_and_held                 1\n",
      "Ian Walsh                      1\n",
      "BunyipPouch                    1\n",
      "Alejandro Guerra-Manzanares    1\n",
      "lkl34                          1\n",
      "Keith Feldman                  1\n",
      "Maximilian P Niroomand         1\n",
      "NewSomethingUnlocked           1\n",
      "Iddo Drori                     1\n",
      "stanley_john                   1\n",
      "Davide Cacciarelli             1\n",
      "Hertz314159                    1\n",
      "Jessica Zosa Forde             1\n",
      "Feras A. Batarseh              1\n",
      "Working_Dress9277              1\n",
      "Keyang Xu                      1\n",
      "Name: auteur, dtype: int64\n",
      "\n",
      "Nombre total d'auteurs uniques : 47\n"
     ]
    }
   ],
   "source": [
    "# Distribution des auteurs\n",
    "print(\"Distribution des auteurs :\")\n",
    "print(df_discours['auteur'].value_counts())\n",
    "\n",
    "print(f\"\\nNombre total d'auteurs uniques : {df_discours['auteur'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 - Création du corpus avec découpage en phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traitement: 100%|██████████| 49/49 [00:00<00:00, 2753.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Création du corpus avec découpage en phrases...\n",
      "\n",
      "Corpus 'Corpus Discours US' : 292 documents, 47 auteurs\n",
      "Nombre total de phrases créées : 292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def decouper_en_phrases(texte):\n",
    "    \"\"\"Découpe un texte en phrases.\"\"\"\n",
    "    phrases = re.split(r'[.!?]+', texte)\n",
    "    phrases = [p.strip() for p in phrases if p.strip() and len(p.strip()) > 20]\n",
    "    return phrases\n",
    "\n",
    "# Création du corpus\n",
    "corpus_discours = Corpus(\"Corpus Discours US\")\n",
    "\n",
    "print(\"Création du corpus avec découpage en phrases...\")\n",
    "phrase_count = 0\n",
    "\n",
    "for idx, row in tqdm(df_discours.iterrows(), total=len(df_discours), desc=\"Traitement\"):\n",
    "    texte = str(row['texte'])\n",
    "    phrases = decouper_en_phrases(texte)\n",
    "    \n",
    "    for i, phrase in enumerate(phrases):\n",
    "        titre_phrase = f\"{row['titre']} - Phrase {i+1}\"\n",
    "        \n",
    "        doc = DocumentFactory.create_document(\n",
    "            doc_type=row.get('type', 'document').lower(),\n",
    "            titre=titre_phrase,\n",
    "            auteur=row['auteur'],\n",
    "            date=row['date'],\n",
    "            url=row.get('url', ''),\n",
    "            texte=phrase\n",
    "        )\n",
    "        \n",
    "        corpus_discours.add(doc)\n",
    "        phrase_count += 1\n",
    "\n",
    "print(f\"\\n{corpus_discours}\")\n",
    "print(f\"Nombre total de phrases créées : {phrase_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 - Test des fonctions search et concorde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TEST DE LA FONCTION SEARCH\n",
      "================================================================================\n",
      "\n",
      "Passages contenant 'learning' : 112\n",
      "\n",
      "Affichage des 5 premiers :\n",
      "\n",
      "1. ...I switched to Machine Learning and I am LOST Hello everybody, I'm a bit lost and...\n",
      "\n",
      "2. ... called AI, which focuses on AI logic and Machine Learning I found this really exciting, so even after learn...\n",
      "\n",
      "3. ... start my journey Best resources to learn Machine Learning deeply in 2–3 months Hey everyone,  I’m planning ...\n",
      "\n",
      "4. ...pend the next 2–3 months fully focused on Machine Learning I already know Python, NumPy, Pandas, Matplotlib,...\n",
      "\n",
      "5. ...ly part I really want to dive into now is Machine Learning itself What I’m looking for are resources that go...\n"
     ]
    }
   ],
   "source": [
    "# Test de la fonction search\n",
    "print(\"=\"*80)\n",
    "print(\"TEST DE LA FONCTION SEARCH\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "mot_recherche = \"learning\"\n",
    "passages = corpus_discours.search(mot_recherche)\n",
    "\n",
    "print(f\"\\nPassages contenant '{mot_recherche}' : {len(passages)}\")\n",
    "print(f\"\\nAffichage des 5 premiers :\")\n",
    "for i, passage in enumerate(passages[:5], 1):\n",
    "    print(f\"\\n{i}. ...{passage}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TEST DE LA FONCTION CONCORDE\n",
      "================================================================================\n",
      "\n",
      "Occurrences de 'machine' : 95\n",
      "\n",
      "Affichage des 10 premières :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contexte gauche</th>\n",
       "      <th>motif trouvé</th>\n",
       "      <th>contexte droit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I switched to</td>\n",
       "      <td>Machine</td>\n",
       "      <td>Learning and I am LOST Hello everybody,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alled AI, which focuses on AI logic and</td>\n",
       "      <td>Machine</td>\n",
       "      <td>Learning I found this really exciting,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tart my journey Best resources to learn</td>\n",
       "      <td>Machine</td>\n",
       "      <td>Learning deeply in 2–3 months Hey every</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nd the next 2–3 months fully focused on</td>\n",
       "      <td>Machine</td>\n",
       "      <td>Learning I already know Python, NumPy,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>part I really want to dive into now is</td>\n",
       "      <td>Machine</td>\n",
       "      <td>Learning itself What I’m looking for ar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>, what resources would you rely on Is a</td>\n",
       "      <td>machine</td>\n",
       "      <td>learning career still good Hi I’m 17 an</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>into the AI industry, specifically as a</td>\n",
       "      <td>machine</td>\n",
       "      <td>learning engineer I have a genuine inte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>should help me work towards becoming a</td>\n",
       "      <td>machine</td>\n",
       "      <td>learning engineer) If it is not a good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>do mechanical engineering Getting into</td>\n",
       "      <td>Machine</td>\n",
       "      <td>Learning Hello,  I have a background in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>echanical Engineering and want to learn</td>\n",
       "      <td>Machine</td>\n",
       "      <td>Learning from scratch Where should I st</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            contexte gauche motif trouvé  \\\n",
       "0                            I switched to       Machine   \n",
       "1  alled AI, which focuses on AI logic and       Machine   \n",
       "2  tart my journey Best resources to learn       Machine   \n",
       "3  nd the next 2–3 months fully focused on       Machine   \n",
       "4   part I really want to dive into now is       Machine   \n",
       "5  , what resources would you rely on Is a       machine   \n",
       "6  into the AI industry, specifically as a       machine   \n",
       "7   should help me work towards becoming a       machine   \n",
       "8   do mechanical engineering Getting into       Machine   \n",
       "9  echanical Engineering and want to learn       Machine   \n",
       "\n",
       "                             contexte droit  \n",
       "0   Learning and I am LOST Hello everybody,  \n",
       "1   Learning I found this really exciting,   \n",
       "2   Learning deeply in 2–3 months Hey every  \n",
       "3   Learning I already know Python, NumPy,   \n",
       "4   Learning itself What I’m looking for ar  \n",
       "5   learning career still good Hi I’m 17 an  \n",
       "6   learning engineer I have a genuine inte  \n",
       "7   learning engineer) If it is not a good   \n",
       "8   Learning Hello,  I have a background in  \n",
       "9   Learning from scratch Where should I st  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test de la fonction concorde\n",
    "print(\"=\"*80)\n",
    "print(\"TEST DE LA FONCTION CONCORDE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "expression = \"machine\"\n",
    "df_concorde = corpus_discours.concorde(expression, taille_contexte=40)\n",
    "\n",
    "print(f\"\\nOccurrences de '{expression}' : {len(df_concorde)}\")\n",
    "print(f\"\\nAffichage des 10 premières :\")\n",
    "display(df_concorde.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Partie 2 : Utilisation du moteur de recherche\n",
    "## 2.1 - Import et initialisation du SearchEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialisation du moteur de recherche...\n",
      "\n",
      "Moteur initialisé avec succès !\n",
      "\n",
      "Statistiques du vocabulaire :\n",
      "Taille du vocabulaire : 1744 mots\n",
      "\n",
      "Exemple de mots dans le vocabulaire :\n",
      "  - a : 136 occurrences, 96 documents\n",
      "  - abduction : 1 occurrences, 1 documents\n",
      "  - ability : 5 occurrences, 4 documents\n",
      "  - able : 1 occurrences, 1 documents\n",
      "  - about : 3 occurrences, 3 documents\n",
      "  - academic : 1 occurrences, 1 documents\n",
      "  - accessibility : 1 occurrences, 1 documents\n",
      "  - accessible : 1 occurrences, 1 documents\n",
      "  - according : 2 occurrences, 2 documents\n",
      "  - accounted : 2 occurrences, 2 documents\n"
     ]
    }
   ],
   "source": [
    "# Initialisation du moteur de recherche\n",
    "print(\"Initialisation du moteur de recherche...\\n\")\n",
    "\n",
    "moteur = SearchEngine(corpus_discours)\n",
    "\n",
    "print(\"Moteur initialisé avec succès !\")\n",
    "print(\"\\nStatistiques du vocabulaire :\")\n",
    "moteur.afficher_stats_vocab()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 - Test avec plusieurs requêtes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Requête : 'machine learning'\n",
      "================================================================================\n",
      "\n",
      "5 résultats trouvés :\n",
      "\n",
      "1. [Reddit] This machine learning method... - Phrase 1\n",
      "   Auteur: NewSomethingUnlocked\n",
      "   Score: 0.3647\n",
      "\n",
      "2. [Arxiv] Automatic Machine Learning by Pipeline Synthesis using Model-Based Reinforcement Learning and a Grammar - Phrase 1\n",
      "   Auteur: Iddo Drori\n",
      "   Score: 0.2836\n",
      "\n",
      "3. [Reddit] Machine learning engineer, 31M - Phrase 1\n",
      "   Auteur: gaeioran\n",
      "   Score: 0.2719\n",
      "\n",
      "4. [Reddit] XKCD Machine Learning - Phrase 1\n",
      "   Auteur: loved_and_held\n",
      "   Score: 0.2572\n",
      "\n",
      "5. [Reddit] Machine Learning Magic. - Phrase 1\n",
      "   Auteur: esberat\n",
      "   Score: 0.2572\n",
      "\n",
      "================================================================================\n",
      "Requête : 'neural network'\n",
      "================================================================================\n",
      "\n",
      "5 résultats trouvés :\n",
      "\n",
      "1. [Arxiv] Automatic Machine Learning by Pipeline Synthesis using Model-Based Reinforcement Learning and a Grammar - Phrase 2\n",
      "   Auteur: Iddo Drori\n",
      "   Score: 0.2028\n",
      "\n",
      "2. [Arxiv] TapNet: Neural Network Augmented with Task-Adaptive Projection for Few-Shot Learning - Phrase 2\n",
      "   Auteur: Sung Whan Yoon\n",
      "   Score: 0.1866\n",
      "\n",
      "3. [Reddit] I switched to Machine Learning and I am LOST - Phrase 4\n",
      "   Auteur: Hertz314159\n",
      "   Score: 0.1858\n",
      "\n",
      "4. [Arxiv] TapNet: Neural Network Augmented with Task-Adaptive Projection for Few-Shot Learning - Phrase 3\n",
      "   Auteur: Sung Whan Yoon\n",
      "   Score: 0.1731\n",
      "\n",
      "5. [Reddit] Best resources to learn Machine Learning deeply in 2–3 months? - Phrase 6\n",
      "   Auteur: vansh596\n",
      "   Score: 0.1598\n",
      "\n",
      "================================================================================\n",
      "Requête : 'data science'\n",
      "================================================================================\n",
      "\n",
      "5 résultats trouvés :\n",
      "\n",
      "1. [Reddit] Is a machine learning career still good? - Phrase 4\n",
      "   Auteur: BBBixncx\n",
      "   Score: 0.3699\n",
      "\n",
      "2. [Arxiv] Changing Data Sources in the Age of Machine Learning for Official Statistics - Phrase 3\n",
      "   Auteur: Cedric De Boom\n",
      "   Score: 0.2819\n",
      "\n",
      "3. [Arxiv] Changing Data Sources in the Age of Machine Learning for Official Statistics - Phrase 1\n",
      "   Auteur: Cedric De Boom\n",
      "   Score: 0.2565\n",
      "\n",
      "4. [Reddit] I switched to Machine Learning and I am LOST - Phrase 2\n",
      "   Auteur: Hertz314159\n",
      "   Score: 0.2510\n",
      "\n",
      "5. [Arxiv] Multimodal Machine Learning for Automated ICD Coding - Phrase 10\n",
      "   Auteur: Keyang Xu\n",
      "   Score: 0.2370\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test avec différentes requêtes\n",
    "requetes_test = [\n",
    "    \"machine learning\",\n",
    "    \"neural network\",\n",
    "    \"data science\"\n",
    "]\n",
    "\n",
    "for requete in requetes_test:\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Requête : '{requete}'\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    resultats = moteur.search(requete, nb_resultats=5)\n",
    "    \n",
    "    if len(resultats) > 0:\n",
    "        print(f\"\\n{len(resultats)} résultats trouvés :\\n\")\n",
    "        for idx, row in resultats.iterrows():\n",
    "            print(f\"{idx+1}. [{row['type']}] {row['titre']}\")\n",
    "            print(f\"   Auteur: {row['auteur']}\")\n",
    "            print(f\"   Score: {row['score']:.4f}\\n\")\n",
    "    else:\n",
    "        print(\"Aucun résultat trouvé.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 - Ajout compteur avec tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test avec barre de progression :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Récupération: 100%|██████████| 10/10 [00:00<00:00, 60611.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Traitement de la requête...\n",
      "\n",
      "10 résultats :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titre</th>\n",
       "      <th>auteur</th>\n",
       "      <th>score</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This machine learning method... - Phrase 1</td>\n",
       "      <td>NewSomethingUnlocked</td>\n",
       "      <td>0.364688</td>\n",
       "      <td>Reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Automatic Machine Learning by Pipeline Synthes...</td>\n",
       "      <td>Iddo Drori</td>\n",
       "      <td>0.283620</td>\n",
       "      <td>Arxiv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Machine learning engineer, 31M - Phrase 1</td>\n",
       "      <td>gaeioran</td>\n",
       "      <td>0.271937</td>\n",
       "      <td>Reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XKCD Machine Learning - Phrase 1</td>\n",
       "      <td>loved_and_held</td>\n",
       "      <td>0.257243</td>\n",
       "      <td>Reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Machine Learning Magic. - Phrase 1</td>\n",
       "      <td>esberat</td>\n",
       "      <td>0.257243</td>\n",
       "      <td>Reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>How do you learn machine learning? - Phrase 1</td>\n",
       "      <td>ShortImplement4486</td>\n",
       "      <td>0.229862</td>\n",
       "      <td>Reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Is machine learning a good career in 2025? - P...</td>\n",
       "      <td>stanley_john</td>\n",
       "      <td>0.223631</td>\n",
       "      <td>Reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Emotion in Reinforcement Learning Agents and R...</td>\n",
       "      <td>Thomas M. Moerland</td>\n",
       "      <td>0.215450</td>\n",
       "      <td>Arxiv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Getting into Machine Learning - Phrase 1</td>\n",
       "      <td>Working_Dress9277</td>\n",
       "      <td>0.212482</td>\n",
       "      <td>Reddit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Teaching Uncertainty Quantification in Machine...</td>\n",
       "      <td>Matias Valdenegro-Toro</td>\n",
       "      <td>0.208356</td>\n",
       "      <td>Arxiv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               titre                  auteur  \\\n",
       "0         This machine learning method... - Phrase 1    NewSomethingUnlocked   \n",
       "1  Automatic Machine Learning by Pipeline Synthes...              Iddo Drori   \n",
       "2          Machine learning engineer, 31M - Phrase 1                gaeioran   \n",
       "3                   XKCD Machine Learning - Phrase 1          loved_and_held   \n",
       "4                 Machine Learning Magic. - Phrase 1                 esberat   \n",
       "5      How do you learn machine learning? - Phrase 1      ShortImplement4486   \n",
       "6  Is machine learning a good career in 2025? - P...            stanley_john   \n",
       "7  Emotion in Reinforcement Learning Agents and R...      Thomas M. Moerland   \n",
       "8           Getting into Machine Learning - Phrase 1       Working_Dress9277   \n",
       "9  Teaching Uncertainty Quantification in Machine...  Matias Valdenegro-Toro   \n",
       "\n",
       "      score    type  \n",
       "0  0.364688  Reddit  \n",
       "1  0.283620   Arxiv  \n",
       "2  0.271937  Reddit  \n",
       "3  0.257243  Reddit  \n",
       "4  0.257243  Reddit  \n",
       "5  0.229862  Reddit  \n",
       "6  0.223631  Reddit  \n",
       "7  0.215450   Arxiv  \n",
       "8  0.212482  Reddit  \n",
       "9  0.208356   Arxiv  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Version avec barre de progression\n",
    "def search_with_progress(self, mots_clefs, nb_resultats=10):\n",
    "    print(\"Traitement de la requête...\")\n",
    "    \n",
    "    vecteur_requete = self._vectoriser_requete(mots_clefs)\n",
    "    scores = self._similarite_cosinus(vecteur_requete, self.mat_TFxIDF)\n",
    "    indices_tries = np.argsort(scores)[::-1][:nb_resultats]\n",
    "    \n",
    "    resultats = []\n",
    "    for idx in tqdm(indices_tries, desc=\"Récupération\"):\n",
    "        if scores[idx] > 0:\n",
    "            doc = self.corpus.id2doc[idx]\n",
    "            resultats.append({\n",
    "                'doc_id': idx,\n",
    "                'titre': doc.titre,\n",
    "                'auteur': doc.auteur,\n",
    "                'date': doc.date,\n",
    "                'url': doc.url,\n",
    "                'score': scores[idx],\n",
    "                'type': doc.getType()\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(resultats)\n",
    "\n",
    "import types\n",
    "moteur.search_with_progress = types.MethodType(search_with_progress, moteur)\n",
    "\n",
    "# Test\n",
    "print(\"Test avec barre de progression :\\n\")\n",
    "resultats = moteur.search_with_progress(\"machine learning\", nb_resultats=10)\n",
    "\n",
    "if len(resultats) > 0:\n",
    "    print(f\"\\n{len(resultats)} résultats :\")\n",
    "    display(resultats[['titre', 'auteur', 'score', 'type']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Partie 3 : Interface graphique\n",
    "## 3.1 - Création des objets graphiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Widgets créés !\n"
     ]
    }
   ],
   "source": [
    "# Widgets de base\n",
    "titre_label = widgets.Label(\n",
    "    value='Moteur de recherche'\n",
    ")\n",
    "\n",
    "mots_cles_text = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='mot1 mot2 mot3',\n",
    "    description='Mots clés :',\n",
    "    layout=widgets.Layout(width='500px')\n",
    ")\n",
    "\n",
    "nb_docs_slider = widgets.IntSlider(\n",
    "    value=10,\n",
    "    min=1,\n",
    "    max=50,\n",
    "    description=\"Nombre d'articles à extraire :\",\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='500px')\n",
    ")\n",
    "\n",
    "print(\"Widgets créés !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 - Affichage avec VBox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5df40b5053849fea95171e93dcc43e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Moteur de recherche'), Text(value='', description='Mots clés :', layout=Layout(wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interface_simple = widgets.VBox([\n",
    "    titre_label,\n",
    "    mots_cles_text,\n",
    "    nb_docs_slider\n",
    "])\n",
    "\n",
    "display(interface_simple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 - Ajout de l'objet Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42c9ee9b0a214388b25938198512528d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Moteur de recherche'), Text(value='', description='Mots clés :', layout=Layout(wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sortie_resultats = widgets.Output()\n",
    "\n",
    "interface_output = widgets.VBox([\n",
    "    titre_label,\n",
    "    mots_cles_text,\n",
    "    nb_docs_slider,\n",
    "    sortie_resultats\n",
    "])\n",
    "\n",
    "display(interface_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 - Ajout du bouton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3d0821b175144698f3b5305a0d3f8d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Moteur de recherche'), Text(value='', description='Mots clés :', layout=Layout(wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bouton_recherche = widgets.Button(\n",
    "    description='Rechercher',\n",
    "    button_style='primary',\n",
    "    tooltip='Lancer la recherche',\n",
    "    icon='search'\n",
    ")\n",
    "\n",
    "interface_bouton = widgets.VBox([\n",
    "    titre_label,\n",
    "    mots_cles_text,\n",
    "    nb_docs_slider,\n",
    "    bouton_recherche,\n",
    "    sortie_resultats\n",
    "])\n",
    "\n",
    "display(interface_bouton)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 - Fonction clique_bouton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fonction configurée !\n"
     ]
    }
   ],
   "source": [
    "def clique_bouton(b):\n",
    "    requete = mots_cles_text.value\n",
    "    nb_resultats = nb_docs_slider.value\n",
    "    \n",
    "    sortie_resultats.clear_output()\n",
    "    \n",
    "    with sortie_resultats:\n",
    "        if not requete.strip():\n",
    "            print(\" Veuillez entrer des mots clés.\")\n",
    "            return\n",
    "        \n",
    "        print(f\" Recherche : '{requete}'\")\n",
    "        print(f\" Nombre de résultats : {nb_resultats}\")\n",
    "        print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "        \n",
    "        try:\n",
    "            resultats = moteur.search(requete, nb_resultats=nb_resultats)\n",
    "            \n",
    "            if len(resultats) > 0:\n",
    "                print(f\" {len(resultats)} résultats trouvés :\\n\")\n",
    "                \n",
    "                for idx, row in resultats.iterrows():\n",
    "                    print(f\"  Résultat {idx+1}\")\n",
    "                    print(f\"   Type: [{row['type']}]\")\n",
    "                    print(f\"   Titre: {row['titre']}\")\n",
    "                    print(f\"   Auteur: {row['auteur']}\")\n",
    "                    print(f\"   Score: {row['score']:.4f}\")\n",
    "                    print(f\"   URL: {row['url']}\")\n",
    "                    print(\"\\n\" + \"-\"*80 + \"\\n\")\n",
    "                \n",
    "                print(\"\\n Tableau récapitulatif :\\n\")\n",
    "                display(resultats[['titre', 'auteur', 'score', 'type']])\n",
    "                \n",
    "            else:\n",
    "                print(\" Aucun résultat trouvé.\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\" Erreur : {str(e)}\")\n",
    "\n",
    "bouton_recherche.on_click(clique_bouton)\n",
    "print(\"Fonction configurée !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 - Interface complète"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interface de recherche complète :\n",
      "Entrez vos mots clés et cliquez sur 'Rechercher'\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e8978b320a742c6b975798542a1b6da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Moteur de recherche'), HTML(value='<hr>'), Text(value='', description='Mots clés :…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Interface de recherche complète :\")\n",
    "print(\"Entrez vos mots clés et cliquez sur 'Rechercher'\\n\")\n",
    "\n",
    "interface_complete = widgets.VBox([\n",
    "    titre_label,\n",
    "    widgets.HTML(value=\"<hr>\"),\n",
    "    mots_cles_text,\n",
    "    nb_docs_slider,\n",
    "    bouton_recherche,\n",
    "    widgets.HTML(value=\"<hr>\"),\n",
    "    sortie_resultats\n",
    "], layout=widgets.Layout(padding='10px', border='2px solid #ccc'))\n",
    "\n",
    "display(interface_complete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7 - Interface avancée avec filtres "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interface avancée avec filtres :\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76cf1f4966a24b7c84b339cefad93a86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Moteur de recherche avancé'), HTML(value='<hr>'), Text(value='', description='Mots…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Interface avancée avec filtres\n",
    "auteurs_uniques = ['Tous'] + sorted(list(set([doc.auteur for doc in corpus_discours.id2doc.values()])))\n",
    "\n",
    "titre_avance = widgets.Label(value='Moteur de recherche avancé')\n",
    "\n",
    "filtre_auteur = widgets.Dropdown(\n",
    "    options=auteurs_uniques,\n",
    "    value='Tous',\n",
    "    description='Auteur :'\n",
    ")\n",
    "\n",
    "filtre_type = widgets.Dropdown(\n",
    "    options=['Tous', 'Reddit', 'Arxiv', 'Document'],\n",
    "    value='Tous',\n",
    "    description='Type :'\n",
    ")\n",
    "\n",
    "mots_cles_avance = widgets.Text(\n",
    "    placeholder='mot1 mot2 mot3',\n",
    "    description='Mots clés :',\n",
    "    layout=widgets.Layout(width='500px')\n",
    ")\n",
    "\n",
    "nb_docs_avance = widgets.IntSlider(\n",
    "    value=10,\n",
    "    min=1,\n",
    "    max=50,\n",
    "    description=\"Nombre :\",\n",
    "    layout=widgets.Layout(width='500px')\n",
    ")\n",
    "\n",
    "bouton_avance = widgets.Button(\n",
    "    description='Rechercher',\n",
    "    button_style='success',\n",
    "    icon='search'\n",
    ")\n",
    "\n",
    "sortie_avance = widgets.Output()\n",
    "\n",
    "def recherche_avancee(b):\n",
    "    requete = mots_cles_avance.value\n",
    "    nb_resultats = nb_docs_avance.value\n",
    "    auteur_filtre = filtre_auteur.value\n",
    "    type_filtre = filtre_type.value\n",
    "    \n",
    "    sortie_avance.clear_output()\n",
    "    \n",
    "    with sortie_avance:\n",
    "        if not requete.strip():\n",
    "            print(\" Entrez des mots clés.\")\n",
    "            return\n",
    "        \n",
    "        print(f\"  Recherche avancée\")\n",
    "        print(f\"   Requête : '{requete}'\")\n",
    "        print(f\"   Filtre auteur : {auteur_filtre}\")\n",
    "        print(f\"   Filtre type : {type_filtre}\")\n",
    "        print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "        \n",
    "        try:\n",
    "            resultats = moteur.search(requete, nb_resultats=nb_resultats*3)\n",
    "            \n",
    "            # return if no results\n",
    "            if len(resultats) == 0:\n",
    "                print(\" Aucun résultat.\")\n",
    "                return\n",
    "            \n",
    "            if auteur_filtre != 'Tous':\n",
    "                resultats = resultats[resultats['auteur'] == auteur_filtre]\n",
    "            \n",
    "            if type_filtre != 'Tous':\n",
    "                resultats = resultats[resultats['type'] == type_filtre]\n",
    "            \n",
    "            resultats = resultats.head(nb_resultats)\n",
    "            \n",
    "            if len(resultats) > 0:\n",
    "                print(f\" {len(resultats)} résultats après filtrage :\\n\")\n",
    "                \n",
    "                for idx, row in resultats.iterrows():\n",
    "                    print(f\"  {idx+1}. [{row['type']}] {row['titre']}\")\n",
    "                    print(f\"   Auteur: {row['auteur']}\")\n",
    "                    print(f\"   Score: {row['score']:.4f}\\n\")\n",
    "                \n",
    "                print(\"\\n Tableau :\")\n",
    "                display(resultats[['titre', 'auteur', 'score', 'type']])\n",
    "            else:\n",
    "                print(\" Aucun résultat.\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\" Erreur : {e}\")\n",
    "\n",
    "bouton_avance.on_click(recherche_avancee)\n",
    "\n",
    "interface_avancee = widgets.VBox([\n",
    "    titre_avance,\n",
    "    widgets.HTML(value=\"<hr>\"),\n",
    "    mots_cles_avance,\n",
    "    widgets.HBox([filtre_auteur, filtre_type]),\n",
    "    nb_docs_avance,\n",
    "    bouton_avance,\n",
    "    widgets.HTML(value=\"<hr>\"),\n",
    "    sortie_avance\n",
    "], layout=widgets.Layout(padding='15px', border='3px solid #4CAF50'))\n",
    "\n",
    "print(\"Interface avancée avec filtres :\")\n",
    "display(interface_avancee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents par type:\n",
      "Arxiv     183\n",
      "Reddit    109\n",
      "Name: type, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>texte</th>\n",
       "      <th>type</th>\n",
       "      <th>year_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-10-29 01:46:28</td>\n",
       "      <td>i switched to machine learning and i am lost h...</td>\n",
       "      <td>Reddit</td>\n",
       "      <td>2025-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-10-29 01:46:28</td>\n",
       "      <td>i m in a year computer science program</td>\n",
       "      <td>Reddit</td>\n",
       "      <td>2025-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-10-29 01:46:28</td>\n",
       "      <td>the first years cover general programming and ...</td>\n",
       "      <td>Reddit</td>\n",
       "      <td>2025-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-10-29 01:46:28</td>\n",
       "      <td>we had two specializations software and networ...</td>\n",
       "      <td>Reddit</td>\n",
       "      <td>2025-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-10-29 01:46:28</td>\n",
       "      <td>i found this really exciting so even after lea...</td>\n",
       "      <td>Reddit</td>\n",
       "      <td>2025-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date                                              texte  \\\n",
       "0 2025-10-29 01:46:28  i switched to machine learning and i am lost h...   \n",
       "1 2025-10-29 01:46:28             i m in a year computer science program   \n",
       "2 2025-10-29 01:46:28  the first years cover general programming and ...   \n",
       "3 2025-10-29 01:46:28  we had two specializations software and networ...   \n",
       "4 2025-10-29 01:46:28  i found this really exciting so even after lea...   \n",
       "\n",
       "     type year_month  \n",
       "0  Reddit    2025-10  \n",
       "1  Reddit    2025-10  \n",
       "2  Reddit    2025-10  \n",
       "3  Reddit    2025-10  \n",
       "4  Reddit    2025-10  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Préparation des données temporelles avec type de document\n",
    "data = []\n",
    "\n",
    "for doc in corpus_discours.id2doc.values():\n",
    "    if doc.date is not None:\n",
    "        data.append({\n",
    "            \"date\": pd.to_datetime(doc.date),\n",
    "            \"texte\": corpus_discours.nettoyer_texte(doc.texte),\n",
    "            \"type\": doc.getType()\n",
    "        })\n",
    "\n",
    "df_time = pd.DataFrame(data)\n",
    "df_time[\"year_month\"] = df_time[\"date\"].dt.to_period(\"M\")\n",
    "\n",
    "print(f\"Documents par type:\")\n",
    "print(df_time[\"type\"].value_counts())\n",
    "df_time.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evolution_mot_par_type(df, mot, doc_type):\n",
    "    \"\"\"Calcule l'évolution d'un mot par mois pour un type de document\"\"\"\n",
    "    mot = mot.lower()\n",
    "    df_filtered = df[df[\"type\"] == doc_type]\n",
    "    \n",
    "    freq_par_mois = defaultdict(int)\n",
    "    total_par_mois = defaultdict(int)\n",
    "\n",
    "    for _, row in df_filtered.iterrows():\n",
    "        mots = row[\"texte\"].split()\n",
    "        mois = row[\"year_month\"]\n",
    "\n",
    "        total_par_mois[mois] += len(mots)\n",
    "        freq_par_mois[mois] += mots.count(mot)\n",
    "\n",
    "    resultats = []\n",
    "    for mois in sorted(freq_par_mois.keys()):\n",
    "        freq_relative = 0\n",
    "        if total_par_mois[mois] > 0:\n",
    "            freq_relative = freq_par_mois[mois] / total_par_mois[mois]\n",
    "\n",
    "        resultats.append({\n",
    "            \"mois\": mois.to_timestamp(),\n",
    "            \"fréquence\": freq_relative\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(resultats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Période disponible: 2017-05 à 2025-12\n"
     ]
    }
   ],
   "source": [
    "# Widgets pour l'analyse temporelle\n",
    "mot_temps = widgets.Text(\n",
    "    description=\"Mot :\",\n",
    "    placeholder=\"ex: learning\"\n",
    ")\n",
    "\n",
    "# obtenir la plage de dates disponibles\n",
    "all_months = sorted(df_time[\"year_month\"].unique())\n",
    "month_options = [(m.strftime(\"%Y.%m\"), i) for i, m in enumerate(all_months)]\n",
    "\n",
    "# Slider pour la période (avec dates réelles)\n",
    "periode_slider = widgets.SelectionRangeSlider(\n",
    "    options=month_options,\n",
    "    index=(0, len(month_options)-1),\n",
    "    description='Période:',\n",
    "    continuous_update=False,\n",
    "    layout=widgets.Layout(width='600px')\n",
    ")\n",
    "\n",
    "bouton_temps = widgets.Button(\n",
    "    description=\"Évolution temporelle\",\n",
    "    button_style=\"info\"\n",
    ")\n",
    "\n",
    "sortie_temps = widgets.Output()\n",
    "\n",
    "print(f\"Période disponible: {all_months[0]} à {all_months[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def afficher_evolution(b):\n",
    "    with sortie_temps:\n",
    "        sortie_temps.clear_output()\n",
    "\n",
    "        mot = mot_temps.value.strip()\n",
    "        if not mot:\n",
    "            print(\"Veuillez entrer un mot.\")\n",
    "            return\n",
    "\n",
    "        # Récupérer les données pour Arxiv et Reddit\n",
    "        df_arxiv = evolution_mot_par_type(df_time, mot, \"Arxiv\")\n",
    "        df_reddit = evolution_mot_par_type(df_time, mot, \"Reddit\")\n",
    "\n",
    "        if df_arxiv.empty and df_reddit.empty:\n",
    "            print(\"Aucune donnée disponible.\")\n",
    "            return\n",
    "\n",
    "        # Filtrer par période sélectionnée\n",
    "        idx_min, idx_max = periode_slider.value\n",
    "        mois_min = all_months[idx_min]\n",
    "        mois_max = all_months[idx_max]\n",
    "        \n",
    "        if not df_arxiv.empty:\n",
    "            df_arxiv = df_arxiv[(df_arxiv[\"mois\"] >= mois_min.to_timestamp()) & \n",
    "                                (df_arxiv[\"mois\"] <= mois_max.to_timestamp())]\n",
    "        if not df_reddit.empty:\n",
    "            df_reddit = df_reddit[(df_reddit[\"mois\"] >= mois_min.to_timestamp()) & \n",
    "                                  (df_reddit[\"mois\"] <= mois_max.to_timestamp())]\n",
    "\n",
    "        # Créer deux graphiques empilés verticalement\n",
    "        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))\n",
    "\n",
    "        # Graphique Arxiv\n",
    "        if not df_arxiv.empty:\n",
    "            ax1.plot(df_arxiv[\"mois\"], df_arxiv[\"fréquence\"], marker=\"o\", color=\"#FF5722\", linewidth=2)\n",
    "            ax1.fill_between(df_arxiv[\"mois\"], df_arxiv[\"fréquence\"], alpha=0.3, color=\"#FF5722\")\n",
    "            ax1.set_title(f\"Arxiv - '{mot}'\", fontsize=12, fontweight='bold')\n",
    "            ax1.set_ylabel(\"Fréquence relative\")\n",
    "            ax1.tick_params(axis='x', rotation=45)\n",
    "            ax1.grid(True, alpha=0.3)\n",
    "        else:\n",
    "            ax1.text(0.5, 0.5, \"Pas de données Arxiv\", ha='center', va='center', fontsize=14)\n",
    "            ax1.set_title(\"Arxiv\")\n",
    "\n",
    "        # Graphique Reddit\n",
    "        if not df_reddit.empty:\n",
    "            ax2.plot(df_reddit[\"mois\"], df_reddit[\"fréquence\"], marker=\"o\", color=\"#2196F3\", linewidth=2)\n",
    "            ax2.fill_between(df_reddit[\"mois\"], df_reddit[\"fréquence\"], alpha=0.3, color=\"#2196F3\")\n",
    "            ax2.set_title(f\"Reddit - '{mot}'\", fontsize=12, fontweight='bold')\n",
    "            ax2.set_xlabel(\"Mois\")\n",
    "            ax2.set_ylabel(\"Fréquence relative\")\n",
    "            ax2.tick_params(axis='x', rotation=45)\n",
    "            ax2.grid(True, alpha=0.3)\n",
    "        else:\n",
    "            ax2.text(0.5, 0.5, \"Pas de données Reddit\", ha='center', va='center', fontsize=14)\n",
    "            ax2.set_title(\"Reddit\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "bouton_temps.on_click(afficher_evolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f97b005ff22c48428d357b3ff6a28047",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=\"<h3 style='color: #2196F3;'>Analyse temporelle du vocabulaire</h3>\"), HTML(value=\"<…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interface_temps = widgets.VBox([\n",
    "    widgets.HTML(\"<h3 style='color: #2196F3;'>Analyse temporelle du vocabulaire</h3>\"),\n",
    "    widgets.HTML(\"<p>Compare l'évolution d'un mot entre Arxiv et Reddit par mois</p>\"),\n",
    "    mot_temps,\n",
    "    widgets.HTML(\"<p><b>Sélectionnez la période (glissez pour ajuster):</b></p>\"),\n",
    "    periode_slider,\n",
    "    bouton_temps,\n",
    "    sortie_temps\n",
    "], layout=widgets.Layout(\n",
    "    padding='15px',\n",
    "    border='3px solid #2196F3'\n",
    "))\n",
    "\n",
    "display(interface_temps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Analyse avancée du vocabulaire (TF-IDF et BM25)\n",
    "\n",
    "Cette section implémente les mesures **TF-IDF** et **OKAPI-BM25** pour analyser l'importance des mots dans le corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports supplémentaires pour TF-IDF et BM25\n",
    "import math\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnalyseurVocabulaire:\n",
    "    \"\"\"Classe pour analyser le vocabulaire avec TF-IDF et BM25\"\"\"\n",
    "    \n",
    "    def __init__(self, corpus):\n",
    "        self.corpus = corpus\n",
    "        self.docs = list(corpus.id2doc.values())\n",
    "        self.N = len(self.docs)  # Nombre total de documents\n",
    "        self.avgdl = 0  # Longueur moyenne des documents\n",
    "        self.df = {}  # Document frequency pour chaque mot\n",
    "        self.idf = {}  # IDF pour chaque mot\n",
    "        \n",
    "        self._calculer_stats()\n",
    "    \n",
    "    def _calculer_stats(self):\n",
    "        \"\"\"Calcule les statistiques nécessaires (DF, IDF, avgdl)\"\"\"\n",
    "        total_length = 0\n",
    "        doc_freq = Counter()\n",
    "        \n",
    "        for doc in self.docs:\n",
    "            texte_nettoye = self.corpus.nettoyer_texte(doc.texte)\n",
    "            mots = texte_nettoye.split()\n",
    "            total_length += len(mots)\n",
    "            \n",
    "            # Document frequency : nombre de docs contenant chaque mot\n",
    "            mots_uniques = set(mots)\n",
    "            for mot in mots_uniques:\n",
    "                doc_freq[mot] += 1\n",
    "        \n",
    "        self.avgdl = total_length / self.N if self.N > 0 else 0\n",
    "        self.df = doc_freq\n",
    "        \n",
    "        # Calcul de l'IDF\n",
    "        for mot, freq in self.df.items():\n",
    "            self.idf[mot] = math.log((self.N - freq + 0.5) / (freq + 0.5) + 1)\n",
    "    \n",
    "    def calculer_tf(self, texte):\n",
    "        \"\"\"Calcule la fréquence des termes (TF) dans un texte\"\"\"\n",
    "        mots = self.corpus.nettoyer_texte(texte).split()\n",
    "        tf = Counter(mots)\n",
    "        total_mots = len(mots)\n",
    "        \n",
    "        # Normalisation par la longueur du document\n",
    "        for mot in tf:\n",
    "            tf[mot] = tf[mot] / total_mots if total_mots > 0 else 0\n",
    "        \n",
    "        return tf\n",
    "    \n",
    "    def calculer_tfidf(self, texte):\n",
    "        \"\"\"Calcule TF-IDF pour un texte\"\"\"\n",
    "        tf = self.calculer_tf(texte)\n",
    "        tfidf = {}\n",
    "        \n",
    "        for mot, tf_value in tf.items():\n",
    "            idf_value = self.idf.get(mot, 0)\n",
    "            tfidf[mot] = tf_value * idf_value\n",
    "        \n",
    "        return tfidf\n",
    "    \n",
    "    def calculer_bm25(self, texte, k1=1.5, b=0.75):\n",
    "        \"\"\"\n",
    "        Calcule le score BM25 pour un texte\n",
    "        k1 : paramètre de saturation du terme (typiquement entre 1.2 et 2.0)\n",
    "        b : paramètre de normalisation de longueur (typiquement 0.75)\n",
    "        \"\"\"\n",
    "        mots = self.corpus.nettoyer_texte(texte).split()\n",
    "        tf = Counter(mots)\n",
    "        dl = len(mots)  # longueur du document\n",
    "        \n",
    "        bm25_scores = {}\n",
    "        \n",
    "        for mot, freq in tf.items():\n",
    "            if mot in self.idf:\n",
    "                # Formule BM25\n",
    "                idf = self.idf[mot]\n",
    "                numerateur = freq * (k1 + 1)\n",
    "                denominateur = freq + k1 * (1 - b + b * (dl / self.avgdl))\n",
    "                bm25_scores[mot] = idf * (numerateur / denominateur)\n",
    "        \n",
    "        return bm25_scores\n",
    "    \n",
    "    def top_mots_tfidf(self, texte, n=10):\n",
    "        \"\"\"Retourne les n mots avec les scores TF-IDF les plus élevés\"\"\"\n",
    "        tfidf = self.calculer_tfidf(texte)\n",
    "        return sorted(tfidf.items(), key=lambda x: x[1], reverse=True)[:n]\n",
    "    \n",
    "    def top_mots_bm25(self, texte, n=10):\n",
    "        \"\"\"Retourne les n mots avec les scores BM25 les plus élevés\"\"\"\n",
    "        bm25 = self.calculer_bm25(texte)\n",
    "        return sorted(bm25.items(), key=lambda x: x[1], reverse=True)[:n]\n",
    "    \n",
    "    def comparer_corpus(self, texte1, texte2, n=20):\n",
    "        \"\"\"\n",
    "        Compare deux textes (ou sous-corpus) et identifie :\n",
    "        - Mots communs\n",
    "        - Mots spécifiques au texte 1\n",
    "        - Mots spécifiques au texte 2\n",
    "        \"\"\"\n",
    "        tfidf1 = self.calculer_tfidf(texte1)\n",
    "        tfidf2 = self.calculer_tfidf(texte2)\n",
    "        \n",
    "        mots1 = set(tfidf1.keys())\n",
    "        mots2 = set(tfidf2.keys())\n",
    "        \n",
    "        # Mots communs\n",
    "        communs = mots1.intersection(mots2)\n",
    "        communs_scores = [(mot, tfidf1[mot], tfidf2[mot]) for mot in communs]\n",
    "        communs_scores.sort(key=lambda x: x[1] + x[2], reverse=True)\n",
    "        \n",
    "        # Mots spécifiques\n",
    "        specifiques1 = [(mot, tfidf1[mot]) for mot in mots1 - mots2]\n",
    "        specifiques1.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        specifiques2 = [(mot, tfidf2[mot]) for mot in mots2 - mots1]\n",
    "        specifiques2.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        return {\n",
    "            'communs': communs_scores[:n],\n",
    "            'specifiques_1': specifiques1[:n],\n",
    "            'specifiques_2': specifiques2[:n]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialisation de l'analyseur de vocabulaire...\n",
      "✓ Analyseur prêt ! (N=292 docs, avgdl=20.42 mots)\n"
     ]
    }
   ],
   "source": [
    "# Initialisation de l'analyseur de vocabulaire\n",
    "print(\"Initialisation de l'analyseur de vocabulaire...\")\n",
    "analyseur = AnalyseurVocabulaire(corpus_discours)\n",
    "print(f\"✓ Analyseur prêt ! (N={analyseur.N} docs, avgdl={analyseur.avgdl:.2f} mots)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interface d'analyse TF-IDF/BM25 :\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3f893d0959447bc82d215a1379b50eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=\"<h3 style='color: #FF5722;'> Analyse TF-IDF et BM25</h3>\"), HTML(value='<hr>'), Tex…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# INTERFACE : Analyse TF-IDF et BM25 d'un document\n",
    "# ============================================================\n",
    "\n",
    "titre_analyse = widgets.HTML(\n",
    "    value=\"<h3 style='color: #FF5722;'> Analyse TF-IDF et BM25</h3>\"\n",
    ")\n",
    "\n",
    "texte_analyse = widgets.Textarea(\n",
    "    placeholder=\"Collez un texte à analyser ici...\",\n",
    "    description=\"Texte :\",\n",
    "    layout=widgets.Layout(width='100%', height='150px')\n",
    ")\n",
    "\n",
    "nb_mots_top = widgets.IntSlider(\n",
    "    value=10,\n",
    "    min=5,\n",
    "    max=30,\n",
    "    step=5,\n",
    "    description=\"Top mots :\",\n",
    "    style={'description_width': '100px'}\n",
    ")\n",
    "\n",
    "bouton_analyse = widgets.Button(\n",
    "    description=\"Analyser\",\n",
    "    button_style=\"warning\",\n",
    "    icon='search'\n",
    ")\n",
    "\n",
    "sortie_analyse = widgets.Output()\n",
    "\n",
    "def analyser_document(b):\n",
    "    with sortie_analyse:\n",
    "        sortie_analyse.clear_output()\n",
    "        \n",
    "        texte = texte_analyse.value.strip()\n",
    "        if not texte:\n",
    "            print(\" Veuillez entrer un texte à analyser.\")\n",
    "            return\n",
    "        \n",
    "        n = nb_mots_top.value\n",
    "        \n",
    "        print(\" Analyse en cours...\\n\")\n",
    "        \n",
    "        # TF-IDF\n",
    "        print(\"=\" * 60)\n",
    "        print(\" TOP MOTS PAR TF-IDF\")\n",
    "        print(\"=\" * 60)\n",
    "        top_tfidf = analyseur.top_mots_tfidf(texte, n)\n",
    "        for i, (mot, score) in enumerate(top_tfidf, 1):\n",
    "            print(f\"{i:2d}. {mot:20s} → {score:.4f}\")\n",
    "        \n",
    "        # BM25\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\" TOP MOTS PAR BM25\")\n",
    "        print(\"=\" * 60)\n",
    "        top_bm25 = analyseur.top_mots_bm25(texte, n)\n",
    "        for i, (mot, score) in enumerate(top_bm25, 1):\n",
    "            print(f\"{i:2d}. {mot:20s} → {score:.4f}\")\n",
    "        \n",
    "        # Statistiques\n",
    "        mots = corpus_discours.nettoyer_texte(texte).split()\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\" STATISTIQUES\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"Nombre de mots : {len(mots)}\")\n",
    "        print(f\"Mots uniques : {len(set(mots))}\")\n",
    "        print(f\"Longueur moyenne corpus : {analyseur.avgdl:.2f} mots\")\n",
    "\n",
    "bouton_analyse.on_click(analyser_document)\n",
    "\n",
    "interface_analyse = widgets.VBox([\n",
    "    titre_analyse,\n",
    "    widgets.HTML(value=\"<hr>\"),\n",
    "    texte_analyse,\n",
    "    nb_mots_top,\n",
    "    bouton_analyse,\n",
    "    widgets.HTML(value=\"<hr>\"),\n",
    "    sortie_analyse\n",
    "], layout=widgets.Layout(padding='15px', border='3px solid #FF5722'))\n",
    "\n",
    "print(\"Interface d'analyse TF-IDF/BM25 :\")\n",
    "display(interface_analyse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interface de comparaison de corpus :\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a23d338465140b1bb64bb48dab6d22c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=\"<h3 style='color: #9C27B0;'>Comparaison de deux corpus</h3>\"), HTML(value='<hr>'), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# INTERFACE : Comparaison de deux corpus\n",
    "# ============================================================\n",
    "\n",
    "titre_comparaison = widgets.HTML(\n",
    "    value=\"<h3 style='color: #9C27B0;'>Comparaison de deux corpus</h3>\"\n",
    ")\n",
    "\n",
    "# Sélection du critère de division\n",
    "critere_division = widgets.Dropdown(\n",
    "    options=['auteur', 'type'],\n",
    "    value='type',\n",
    "    description=\"Diviser par :\",\n",
    "    style={'description_width': '100px'}\n",
    ")\n",
    "\n",
    "# Widgets pour sélectionner les deux groupes à comparer\n",
    "groupe1_select = widgets.Dropdown(\n",
    "    description=\"Groupe 1 :\",\n",
    "    style={'description_width': '100px'}\n",
    ")\n",
    "\n",
    "groupe2_select = widgets.Dropdown(\n",
    "    description=\"Groupe 2 :\",\n",
    "    style={'description_width': '100px'}\n",
    ")\n",
    "\n",
    "nb_mots_comparaison = widgets.IntSlider(\n",
    "    value=15,\n",
    "    min=5,\n",
    "    max=30,\n",
    "    step=5,\n",
    "    description=\"Top mots :\",\n",
    "    style={'description_width': '100px'}\n",
    ")\n",
    "\n",
    "bouton_comparer = widgets.Button(\n",
    "    description=\"Comparer\",\n",
    "    button_style=\"success\"\n",
    ")\n",
    "\n",
    "sortie_comparaison = widgets.Output()\n",
    "\n",
    "def mettre_a_jour_groupes(change):\n",
    "    \"\"\"Met à jour les options des dropdowns selon le critère\"\"\"\n",
    "    critere = critere_division.value\n",
    "    \n",
    "    if critere == 'auteur':\n",
    "        auteurs = set()\n",
    "        for doc in corpus_discours.id2doc.values():\n",
    "            if doc.auteur:\n",
    "                auteurs.add(doc.auteur)\n",
    "        options = sorted(list(auteurs))\n",
    "    elif critere == 'type':\n",
    "        types = set()\n",
    "        for doc in corpus_discours.id2doc.values():\n",
    "            if hasattr(doc, 'type') and doc.type:\n",
    "                types.add(doc.type)\n",
    "        options = sorted(list(types))\n",
    "    else:\n",
    "        options = []\n",
    "    \n",
    "    groupe1_select.options = options\n",
    "    groupe2_select.options = options\n",
    "    if len(options) >= 2:\n",
    "        groupe1_select.value = options[0]\n",
    "        groupe2_select.value = options[1] if len(options) > 1 else options[0]\n",
    "\n",
    "# Initialiser les options\n",
    "mettre_a_jour_groupes(None)\n",
    "critere_division.observe(mettre_a_jour_groupes, names='value')\n",
    "\n",
    "def comparer_groupes(b):\n",
    "    with sortie_comparaison:\n",
    "        sortie_comparaison.clear_output()\n",
    "        \n",
    "        critere = critere_division.value\n",
    "        groupe1 = groupe1_select.value\n",
    "        groupe2 = groupe2_select.value\n",
    "        n = nb_mots_comparaison.value\n",
    "        \n",
    "        if not groupe1 or not groupe2:\n",
    "            print(\"Veuillez sélectionner deux groupes.\")\n",
    "            return\n",
    "        \n",
    "        if groupe1 == groupe2:\n",
    "            print(\"Veuillez sélectionner deux groupes différents.\")\n",
    "            return\n",
    "        \n",
    "        print(f\"Comparaison : {groupe1} vs {groupe2}\\n\")\n",
    "        \n",
    "        # Créer deux textes à partir des documents\n",
    "        texte1_parts = []\n",
    "        texte2_parts = []\n",
    "        \n",
    "        for doc in corpus_discours.id2doc.values():\n",
    "            if critere == 'auteur' and doc.auteur == groupe1:\n",
    "                texte1_parts.append(doc.texte)\n",
    "            elif critere == 'auteur' and doc.auteur == groupe2:\n",
    "                texte2_parts.append(doc.texte)\n",
    "            elif critere == 'type' and hasattr(doc, 'type') and doc.type == groupe1:\n",
    "                texte1_parts.append(doc.texte)\n",
    "            elif critere == 'type' and hasattr(doc, 'type') and doc.type == groupe2:\n",
    "                texte2_parts.append(doc.texte)\n",
    "        \n",
    "        texte1 = \" \".join(texte1_parts)\n",
    "        texte2 = \" \".join(texte2_parts)\n",
    "        \n",
    "        if not texte1 or not texte2:\n",
    "            print(\"Un des groupes ne contient aucun document.\")\n",
    "            return\n",
    "        \n",
    "        # Comparaison\n",
    "        resultats = analyseur.comparer_corpus(texte1, texte2, n)\n",
    "        \n",
    "        # Affichage des résultats\n",
    "        print(\"=\" * 70)\n",
    "        print(f\"MOTS SPÉCIFIQUES À : {groupe1}\")\n",
    "        print(\"=\" * 70)\n",
    "        for i, (mot, score) in enumerate(resultats['specifiques_1'], 1):\n",
    "            print(f\"{i:2d}. {mot:25s} → TF-IDF: {score:.4f}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(f\"MOTS SPÉCIFIQUES À : {groupe2}\")\n",
    "        print(\"=\" * 70)\n",
    "        for i, (mot, score) in enumerate(resultats['specifiques_2'], 1):\n",
    "            print(f\"{i:2d}. {mot:25s} → TF-IDF: {score:.4f}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"MOTS COMMUNS (scores combinés)\")\n",
    "        print(\"=\" * 70)\n",
    "        for i, (mot, score1, score2) in enumerate(resultats['communs'], 1):\n",
    "            total = score1 + score2\n",
    "            print(f\"{i:2d}. {mot:25s} → {groupe1}: {score1:.4f} | {groupe2}: {score2:.4f}\")\n",
    "        \n",
    "        # Statistiques\n",
    "        mots1 = corpus_discours.nettoyer_texte(texte1).split()\n",
    "        mots2 = corpus_discours.nettoyer_texte(texte2).split()\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"STATISTIQUES\")\n",
    "        print(\"=\" * 70)\n",
    "        print(f\"{groupe1:25s} → {len(texte1_parts)} docs, {len(mots1)} mots, {len(set(mots1))} mots uniques\")\n",
    "        print(f\"{groupe2:25s} → {len(texte2_parts)} docs, {len(mots2)} mots, {len(set(mots2))} mots uniques\")\n",
    "\n",
    "bouton_comparer.on_click(comparer_groupes)\n",
    "\n",
    "interface_comparaison = widgets.VBox([\n",
    "    titre_comparaison,\n",
    "    widgets.HTML(value=\"<hr>\"),\n",
    "    critere_division,\n",
    "    widgets.HBox([groupe1_select, groupe2_select]),\n",
    "    nb_mots_comparaison,\n",
    "    bouton_comparer,\n",
    "    widgets.HTML(value=\"<hr>\"),\n",
    "    sortie_comparaison\n",
    "], layout=widgets.Layout(padding='15px', border='3px solid #9C27B0'))\n",
    "\n",
    "print(\"Interface de comparaison de corpus :\")\n",
    "display(interface_comparaison)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74fb9b13eb864752a7c316c98baf2d4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Button(button_style='info', description=' Visualiser les scores', style=ButtonStyle()), Output(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# VISUALISATION : Graphiques TF-IDF et BM25\n",
    "# ============================================================\n",
    "\n",
    "def visualiser_scores(texte, n=15):\n",
    "    \"\"\"Crée des graphiques pour comparer TF-IDF et BM25\"\"\"\n",
    "    \n",
    "    top_tfidf = analyseur.top_mots_tfidf(texte, n)\n",
    "    top_bm25 = analyseur.top_mots_bm25(texte, n)\n",
    "    \n",
    "    # Extraction des données\n",
    "    mots_tfidf = [mot for mot, _ in top_tfidf]\n",
    "    scores_tfidf = [score for _, score in top_tfidf]\n",
    "    \n",
    "    mots_bm25 = [mot for mot, _ in top_bm25]\n",
    "    scores_bm25 = [score for _, score in top_bm25]\n",
    "    \n",
    "    # Création des graphiques\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # TF-IDF\n",
    "    ax1.barh(range(len(mots_tfidf)), scores_tfidf, color='#2196F3')\n",
    "    ax1.set_yticks(range(len(mots_tfidf)))\n",
    "    ax1.set_yticklabels(mots_tfidf)\n",
    "    ax1.set_xlabel('Score TF-IDF', fontsize=12)\n",
    "    ax1.set_title('Top mots par TF-IDF', fontsize=14, fontweight='bold')\n",
    "    ax1.invert_yaxis()\n",
    "    ax1.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    # BM25\n",
    "    ax2.barh(range(len(mots_bm25)), scores_bm25, color='#FF5722')\n",
    "    ax2.set_yticks(range(len(mots_bm25)))\n",
    "    ax2.set_yticklabels(mots_bm25)\n",
    "    ax2.set_xlabel('Score BM25', fontsize=12)\n",
    "    ax2.set_title('Top mots par BM25', fontsize=14, fontweight='bold')\n",
    "    ax2.invert_yaxis()\n",
    "    ax2.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Widget pour tester la visualisation\n",
    "bouton_visu = widgets.Button(\n",
    "    description=\" Visualiser les scores\",\n",
    "    button_style=\"info\"\n",
    ")\n",
    "\n",
    "sortie_visu = widgets.Output()\n",
    "\n",
    "def afficher_visualisation(b):\n",
    "    with sortie_visu:\n",
    "        sortie_visu.clear_output()\n",
    "        \n",
    "        texte = texte_analyse.value.strip()\n",
    "        if not texte:\n",
    "            print(\" Veuillez d'abord entrer un texte dans l'interface d'analyse ci-dessus.\")\n",
    "            return\n",
    "        \n",
    "        visualiser_scores(texte, nb_mots_top.value)\n",
    "\n",
    "bouton_visu.on_click(afficher_visualisation)\n",
    "\n",
    "display(widgets.VBox([\n",
    "    bouton_visu,\n",
    "    sortie_visu\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
