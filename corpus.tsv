id	titre	auteur	date	url	texte	type
0	I switched to Machine Learning and I am LOST	Hertz314159	2025-10-29 01:46:28	https://reddit.com/r/learnmachinelearning/comments/1oiqsax/i_switched_to_machine_learning_and_i_am_lost/	I switched to Machine Learning and I am LOST Hello everybody, I'm a bit lost and could use some help.  I'm in a 5-year Computer Science program. The first 3 years cover general programming and math concepts, and the last two are for specialization. We had two specializations (Software and Network Engineering), but this year a new one opened called AI, which focuses on AI logic and Machine Learning. I found this really exciting, so even after learning Back-End development last year, I chose to enroll in this new track.  I have a good background in programming with C++, Java, Go, and Python. I've used Python for data manipulation with Pandas and NumPy, I've studied Data Structures and Algorithms, and I solve problems on LeetCode and Codeforces.  I've seen some roadmaps; some say I should start with math (Linear Algebra, Statistics, and Probability), while others say to start with coding.  By the end of the study year (in about 8 months), I need to complete a final project: creating a model that diagnoses patients based on symptoms.  So, how should I start my journey?	Reddit
1	Best resources to learn Machine Learning deeply in 2â€“3 months?	vansh596	2025-08-18 13:53:27	https://reddit.com/r/learnmachinelearning/comments/1mtjv2v/best_resources_to_learn_machine_learning_deeply/	Best resources to learn Machine Learning deeply in 2â€“3 months? Hey everyone,  Iâ€™m planning to spend the next 2â€“3 months fully focused on Machine Learning. I already know Python, NumPy, Pandas, Matplotlib, Plotly, and the math side (linear algebra, probability, calculus basics), so Iâ€™m not starting from zero. The only part I really want to dive into now is Machine Learning itself.  What Iâ€™m looking for are resources that go deep and clear all concepts properly â€” not just a surface-level intro. Something that makes sure I donâ€™t miss anything important, from supervised/unsupervised learning to neural networks, optimization, and practical applications.  Could you suggest:  Courses / books / YouTube playlists that explain concepts thoroughly.  Practice resources / project ideas to actually apply what I learn.  Any structured study plan or roadmap you personally found effective.   Basically, if you had to master ML in 2â€“3 months with full dedication, what resources would you rely on?  Thanks a lot ðŸ™ 	Reddit
2	Is a machine learning career still good?	BBBixncx	2025-10-12 07:37:00	https://reddit.com/r/AskProgramming/comments/1o4h0v2/is_a_machine_learning_career_still_good/	Is a machine learning career still good? Hi Iâ€™m 17 and I want to go into the AI industry, specifically as a machine learning engineer. I have a genuine interest in the subject, and I love math as well as programming in python (I do computer science right now in school and that is the programming language we learn). Would a computer science, a data science, or an information and technology degree help me in achieving that goal? How are the working hours, salary, and work life balance.  Iâ€™m concerned that the market might be over saturated or it is an industry that is dying down. Specifically in South Africa how is that space, or in the US (the 2 countries I want to study and later work in). Is it a competitive field, and do i need a masters?  Lastly I have 1 more year of Highschool left before university, what are free courses that I could do in the meantime to improve my coding and logical skills, I currently use brilliant. What are some projects I could do to make me a better candidate for university to improve my application and more complex ones for when I start applying for internships and jobs (all the courses and projects should help me work towards becoming a machine learning engineer).  If it is not a good choice what are some careers I could do that involve programming and arenâ€™t as competitive or saturated, I can learn a different language if it requires it. The job should still be high paying or do I scrap the idea and do mechanical engineering.	Reddit
3	Getting into Machine Learning	Working_Dress9277	2025-12-07 18:34:38	https://reddit.com/r/learnmachinelearning/comments/1pgo6xr/getting_into_machine_learning/	Getting into Machine Learning Hello,  I have a background in Mechanical Engineering and want to learn Machine Learning from scratch. Where should I start (Python, linear algebra, statistics, etc.)? And could you recommend some resources (books, YouTube channels, etc.) without getting too sidetracked?	Reddit
4	How do you learn machine learning?	ShortImplement4486	2025-11-18 08:01:41	https://reddit.com/r/computerscience/comments/1p05aon/how_do_you_learn_machine_learning/	"How do you learn machine learning? i see two pathways, one is everyone keeps telling me to learn probability and statistics and all this theoretical stuff, but then when i search up machine learning projects, ppl just import scikit into python and say .train(). done. no theory involved, so where will i implement all this theory i'm supposed to learn? and how do people make their own models? i guess i still don't quite understand what people mean when they say i'm ""doing ml right now"". what does that meaaannnn T-T"	Reddit
5	Is machine learning a good career in 2025?	stanley_john	2025-08-13 13:07:19	https://reddit.com/r/learnmachinelearning/comments/1mp1fnc/is_machine_learning_a_good_career_in_2025/	Is machine learning a good career in 2025? 	Reddit
6	Machine learning engineer, 31M	gaeioran	2025-12-06 06:28:37	https://reddit.com/r/NLSalaris/comments/1pfhdqs/machine_learning_engineer_31m/	Machine learning engineer, 31M  **1. PERSONAL DETAILS**  * Age: 31 * Education: MSc Computer Science * Work experience: 7 years * Civil status: Married * Children: None  **2. EMPLOYER**  * Sector/Industry: Tech * Amount of employees: 4000+ * Multinational?: Yes * Listed company?: Yes  **3. ROLE DETAILS**  * Job title: Machine learning engineer  * Seniority (junior/senior/etc.): Senior+ * Working hours per week: 40 * Average working hours per week including overtime: 20 (very chill work) * Shift work of 9 to 5 (or flexible): fully remote, flexible between 8AM and 6PM * On-call duty?: one week per two months  * Vacation days per year: 28 * Education/training possibilities: No formal training * Responsible for personnel?: No  **4. SALARY**  * Gross salary per month: 9900 * Net salary per month: 5875 * 13th month?: Holiday allowance paid in May * Car/bike provided by the company/fuel card/free public transport?: No * Pension contribution: maybe 5% with employer matching? Itâ€™s paid outside of my net salary and I donâ€™t know how much. I have 0 faith in Dutch pension system. Getting paid when Iâ€™m 80 years old, in an economy that would inevitably decline in a changing world economy? Counting that as 0.  * Insurance?: No * Other benefits (bonusses, stock-/option pacakges, etc.): 15% bonus, 45k yearly vested stocks   **5. MOBILITY**  * City/region of work: fully remote * Distance home-work (KM): 0 * Commuting time home-work: 10 seconds from bed to living room * How do you commute?: walk  * Is your travel compensated?: fully remote * Home office possibilities?: dining table  **6. OTHER**  * How easily can you take an extra day off?: fairly easy  * How much do you love your job? (scale 0-10) And why? 7. Awesome colleagues and line manager, but clueless higher management.  * How stressful is your job? (scale 0-10) And why?: 3. Chill work * What would you advise others who want to pursue the same career? Keep reading, coding, interviewing. But donâ€™t change job too often.  * Any questions from OP to commenters: should I try harder to aim for 40% pay increase? I have an interview process ongoing but the job requires 3 days in office and the company has bad culture according to Blind. * Other comments: Lately I have been thinking my career is in a weird state, I keep hearing people making 300-500k as software engineers, also know friends who struggle at 80k. I feel I shouldnâ€™t be greedy and keep grinding for higher salary, but at the same time I feel Iâ€™m wasting time not trying.  &#x200B;	Reddit
7	"I hate ""my"" ""field"" (machine learning)"	Substantial-Art-2238	2025-04-17 10:23:23	https://reddit.com/r/PhD/comments/1k17rbr/i_hate_my_field_machine_learning/	"I hate ""my"" ""field"" (machine learning) A lot of people (like me) dive  into ML thinking it's about understanding intelligence, learning, or even just clever math â€” and then they wake up buried under a pile of frameworks, configs, random seeds, hyperparameter grids, and Google Colab crashes. And the worst part? No one tells you how undefined the field really is until you're *knee-deep in the swamp.*  In mathematics:  * There's structure. Rigor. A kind of calm beauty in clarity. * You can prove something and *know* itâ€™s true. * You explore the unknown, yes â€” but on solid ground.  In ML:  * You fumble through a foggy mess of tunable knobs and lucky guesses. * â€œReproducibilityâ€ is a fantasy. * Half the field is just â€œwhat worked better for usâ€ and the other half is trying to explain it *after* the fact. * Nobody *really* knows why half of it works, and yet they act like they do."	Reddit
8	How hard is getting an entry level job in Machine Learning/AI Engineering?	Affectionate-Army458	2025-11-23 01:04:14	https://reddit.com/r/cscareerquestions/comments/1p48870/how_hard_is_getting_an_entry_level_job_in_machine/	How hard is getting an entry level job in Machine Learning/AI Engineering? Is it like any other tech job? or does it require high-degree/yoe from other tech jobs?  And would it become alot easier if i had impressive 2-3 projects involving Computer vision, RL, PPO, and other classical ML.	Reddit
9	If you use GMail, AI (Gemini) was turned on yesterday by default and now scans all of your content for machine learning.	lkl34	2025-11-21 10:32:16	https://reddit.com/r/pcmasterrace/comments/1p2uasm/if_you_use_gmail_ai_gemini_was_turned_on/	"If you use GMail, AI (Gemini) was turned on yesterday by default and now scans all of your content for machine learning. If you use GMail, AI (Gemini) was turned on yesterday by default and now scans all of your content for machine learning. To turn off, go to Settings>General and scroll down. Uncheck the box for ""Smart features."" There's other ""Smart"" add-ons as well, but that's the one that reads your content."	Reddit
10	XKCD Machine Learning	loved_and_held	2025-11-07 04:47:57	https://reddit.com/r/CuratedTumblr/comments/1oqk6fd/xkcd_machine_learning/	XKCD Machine Learning 	Reddit
11	This machine learning method...	NewSomethingUnlocked	2025-07-07 15:00:52	https://reddit.com/r/FUCKYOUINPARTICULAR/comments/1lttk5y/this_machine_learning_method/	This machine learning method... 	Reddit
12	Dropout's video hosting platform was just acquired by a firm that uses AI machine learning in their other business.	Canon_Cowboy	2025-09-10 16:44:10	https://reddit.com/r/dropout/comments/1ndg53r/dropouts_video_hosting_platform_was_just_acquired/	Dropout's video hosting platform was just acquired by a firm that uses AI machine learning in their other business. This feels relevant considering everyone's outspokenness on generative AI, machine learning, and the overall shitification of creatives. It's highly probable that Vimeo will start using their users content for such considering it's what Bending Spoons did with WeTransfer already.   I knew Vimeo's days are numbered but this sucks. You either die the (creative)hero or live long enough to see yourself become the (venture capitalist)villain. 	Reddit
13	Machine Learning Magic.	esberat	2022-07-13 15:19:56	https://reddit.com/r/ProgrammerHumor/comments/vy32zd/machine_learning_magic/	Machine Learning Magic. 	Reddit
14	jrDevVsMachineLearning	dstori	2024-02-07 13:36:59	https://reddit.com/r/ProgrammerHumor/comments/1al1yfj/jrdevvsmachinelearning/	jrDevVsMachineLearning 	Reddit
15	New MIT machine learning model shows relaxing quarantine rules will spike COVID-19 cases	maxwellhill	2020-04-18 04:39:33	https://reddit.com/r/worldnews/comments/g3g0ny/new_mit_machine_learning_model_shows_relaxing/	New MIT machine learning model shows relaxing quarantine rules will spike COVID-19 cases 	Reddit
16	Apple's Director of Machine Learning Resigns Due to Return to Office Work	egocentric-video	2022-05-07 21:52:09	https://reddit.com/r/apple/comments/ukkyky/apples_director_of_machine_learning_resigns_due/	Apple's Director of Machine Learning Resigns Due to Return to Office Work 	Reddit
17	QAnon founder may have been identified thanks to machine learning	Sorin61	2022-02-20 07:11:38	https://reddit.com/r/technology/comments/swuhwe/qanon_founder_may_have_been_identified_thanks_to/	QAnon founder may have been identified thanks to machine learning 	Reddit
18	Machine Learning Helped Scientists Create an Enzyme That Breaks Down Plastic at Warp Speed	Sorin61	2022-05-06 16:25:19	https://reddit.com/r/technology/comments/ujon8k/machine_learning_helped_scientists_create_an/	Machine Learning Helped Scientists Create an Enzyme That Breaks Down Plastic at Warp Speed 	Reddit
19	I modified an old machine learning project to detect Barca players goal celebrations	Willing-Arugula3238	2025-08-03 01:08:53	https://reddit.com/r/Barca/comments/1mg40og/i_modified_an_old_machine_learning_project_to/	I modified an old machine learning project to detect Barca players goal celebrations 	Reddit
20	From Hello world to directly Machine Learning?	space-_-man	2020-07-04 10:51:47	https://reddit.com/r/ProgrammerHumor/comments/hl08s3/from_hello_world_to_directly_machine_learning/	From Hello world to directly Machine Learning? 	Reddit
21	Nicolas Cage Can Now Be Put Into Any Movie in History Thanks to A Machine-Learning Algorithm	BunyipPouch	2018-01-31 12:28:55	https://reddit.com/r/movies/comments/7u99bt/nicolas_cage_can_now_be_put_into_any_movie_in/	Nicolas Cage Can Now Be Put Into Any Movie in History Thanks to A Machine-Learning Algorithm 	Reddit
22	New map made with a machine learning algorithm - Botnik Studios	TrapWolf	2018-06-20 21:17:36	https://reddit.com/r/FortNiteBR/comments/8sl424/new_map_made_with_a_machine_learning_algorithm/	New map made with a machine learning algorithm - Botnik Studios 	Reddit
23	Powerful antibiotic discovered using machine learning for first time	legehjernen	2020-02-20 18:39:57	https://reddit.com/r/science/comments/f6wlc2/powerful_antibiotic_discovered_using_machine/	Powerful antibiotic discovered using machine learning for first time 	Reddit
24	Changing Data Sources in the Age of Machine Learning for Official Statistics	Cedric De Boom	2023-06-07 11:08:12	http://arxiv.org/abs/2306.04338v1	Data science has become increasingly essential for the production of official statistics, as it enables the automated collection, processing, and analysis of large amounts of data. With such data science practices in place, it enables more timely, more insightful and more flexible reporting. However, the quality and integrity of data-science-driven statistics rely on the accuracy and reliability of the data sources and the machine learning techniques that support them. In particular, changes in data sources are inevitable to occur and pose significant risks that are crucial to address in the context of machine learning for official statistics.   This paper gives an overview of the main risks, liabilities, and uncertainties associated with changing data sources in the context of machine learning for official statistics. We provide a checklist of the most prevalent origins and causes of changing data sources; not only on a technical level but also regarding ownership, ethics, regulation, and public perception. Next, we highlight the repercussions of changing data sources on statistical reporting. These include technical effects such as concept drift, bias, availability, validity, accuracy and completeness, but also the neutrality and potential discontinuation of the statistical offering. We offer a few important precautionary measures, such as enhancing robustness in both data sourcing and statistical techniques, and thorough monitoring. In doing so, machine learning-based official statistics can maintain integrity, reliability, consistency, and relevance in policy-making, decision-making, and public discourse.	Arxiv
25	DOME: Recommendations for supervised machine learning validation in biology	Ian Walsh	2020-06-25 12:01:39	http://arxiv.org/abs/2006.16189v4	Modern biology frequently relies on machine learning to provide predictions and improve decision processes. There have been recent calls for more scrutiny on machine learning performance and possible limitations. Here we present a set of community-wide recommendations aiming to help establish standards of supervised machine learning validation in biology. Adopting a structured methods description for machine learning based on data, optimization, model, evaluation (DOME) will aim to help both reviewers and readers to better understand and assess the performance and limitations of a method or outcome. The recommendations are formulated as questions to anyone wishing to pursue implementation of a machine learning algorithm. Answers to these questions can be easily included in the supplementary material of published papers.	Arxiv
26	Learning Curves for Decision Making in Supervised Machine Learning: A Survey	Felix Mohr	2022-01-28 14:34:32	http://arxiv.org/abs/2201.12150v2	Learning curves are a concept from social sciences that has been adopted in the context of machine learning to assess the performance of a learning algorithm with respect to a certain resource, e.g., the number of training examples or the number of training iterations. Learning curves have important applications in several machine learning contexts, most notably in data acquisition, early stopping of model training, and model selection. For instance, learning curves can be used to model the performance of the combination of an algorithm and its hyperparameter configuration, providing insights into their potential suitability at an early stage and often expediting the algorithm selection process. Various learning curve models have been proposed to use learning curves for decision making. Some of these models answer the binary decision question of whether a given algorithm at a certain budget will outperform a certain reference performance, whereas more complex models predict the entire learning curve of an algorithm. We contribute a framework that categorises learning curve approaches using three criteria: the decision-making situation they address, the intrinsic learning curve question they answer and the type of resources they use. We survey papers from the literature and classify them into this framework.	Arxiv
27	Active learning for data streams: a survey	Davide Cacciarelli	2023-02-17 14:24:13	http://arxiv.org/abs/2302.08893v4	Online active learning is a paradigm in machine learning that aims to select the most informative data points to label from a data stream. The problem of minimizing the cost associated with collecting labeled observations has gained a lot of attention in recent years, particularly in real-world applications where data is only available in an unlabeled form. Annotating each observation can be time-consuming and costly, making it difficult to obtain large amounts of labeled data. To overcome this issue, many active learning strategies have been proposed in the last decades, aiming to select the most informative observations for labeling in order to improve the performance of machine learning models. These approaches can be broadly divided into two categories: static pool-based and stream-based active learning. Pool-based active learning involves selecting a subset of observations from a closed pool of unlabeled data, and it has been the focus of many surveys and literature reviews. However, the growing availability of data streams has led to an increase in the number of approaches that focus on online active learning, which involves continuously selecting and labeling observations as they arrive in a stream. This work aims to provide an overview of the most recently proposed approaches for selecting the most informative observations from data streams in real time. We review the various techniques that have been proposed and discuss their strengths and limitations, as well as the challenges and opportunities that exist in this area of research.	Arxiv
28	Physics-Inspired Interpretability Of Machine Learning Models	Maximilian P Niroomand	2023-04-05 11:35:17	http://arxiv.org/abs/2304.02381v2	The ability to explain decisions made by machine learning models remains one of the most significant hurdles towards widespread adoption of AI in highly sensitive areas such as medicine, cybersecurity or autonomous driving. Great interest exists in understanding which features of the input data prompt model decision making. In this contribution, we propose a novel approach to identify relevant features of the input data, inspired by methods from the energy landscapes field, developed in the physical sciences. By identifying conserved weights within groups of minima of the loss landscapes, we can identify the drivers of model decision making. Analogues to this idea exist in the molecular sciences, where coordinate invariants or order parameters are employed to identify critical features of a molecule. However, no such approach exists for machine learning loss landscapes. We will demonstrate the applicability of energy landscape methods to machine learning models and give examples, both synthetic and from the real world, for how these methods can help to make models more interpretable.	Arxiv
29	Privacy-preserving machine learning for healthcare: open challenges and future perspectives	Alejandro Guerra-Manzanares	2023-03-27 19:20:51	http://arxiv.org/abs/2303.15563v1	Machine Learning (ML) has recently shown tremendous success in modeling various healthcare prediction tasks, ranging from disease diagnosis and prognosis to patient treatment. Due to the sensitive nature of medical data, privacy must be considered along the entire ML pipeline, from model training to inference. In this paper, we conduct a review of recent literature concerning Privacy-Preserving Machine Learning (PPML) for healthcare. We primarily focus on privacy-preserving training and inference-as-a-service, and perform a comprehensive review of existing trends, identify challenges, and discuss opportunities for future research directions. The aim of this review is to guide the development of private and efficient ML models in healthcare, with the prospects of translating research efforts into real-world settings.	Arxiv
30	A Benchmark Study of Machine Learning Models for Online Fake News Detection	Junaed Younus Khan	2019-05-12 17:15:11	http://arxiv.org/abs/1905.04749v2	The proliferation of fake news and its propagation on social media has become a major concern due to its ability to create devastating impacts. Different machine learning approaches have been suggested to detect fake news. However, most of those focused on a specific type of news (such as political) which leads us to the question of dataset-bias of the models used. In this research, we conducted a benchmark study to assess the performance of different applicable machine learning approaches on three different datasets where we accumulated the largest and most diversified one. We explored a number of advanced pre-trained language models for fake news detection along with the traditional and deep learning ones and compared their performances from different aspects for the first time to the best of our knowledge. We find that BERT and similar pre-trained models perform the best for fake news detection, especially with very small dataset. Hence, these models are significantly better option for languages with limited electronic contents, i.e., training data. We also carried out several analysis based on the models' performance, article's topic, article's length, and discussed different lessons learned from them. We believe that this benchmark study will help the research community to explore further and news sites/blogs to select the most appropriate fake news detection method.	Arxiv
31	Emotion in Reinforcement Learning Agents and Robots: A Survey	Thomas M. Moerland	2017-05-15 11:49:56	http://arxiv.org/abs/1705.05172v1	This article provides the first survey of computational models of emotion in reinforcement learning (RL) agents. The survey focuses on agent/robot emotions, and mostly ignores human user emotions. Emotions are recognized as functional in decision-making by influencing motivation and action selection. Therefore, computational emotion models are usually grounded in the agent's decision making architecture, of which RL is an important subclass. Studying emotions in RL-based agents is useful for three research fields. For machine learning (ML) researchers, emotion models may improve learning efficiency. For the interactive ML and human-robot interaction (HRI) community, emotions can communicate state and enhance user investment. Lastly, it allows affective modelling (AM) researchers to investigate their emotion theories in a successful AI agent class. This survey provides background on emotion theory and RL. It systematically addresses 1) from what underlying dimensions (e.g., homeostasis, appraisal) emotions can be derived and how these can be modelled in RL-agents, 2) what types of emotions have been derived from these dimensions, and 3) how these emotions may either influence the learning efficiency of the agent or be useful as social signals. We also systematically compare evaluation criteria, and draw connections to important RL sub-domains like (intrinsic) motivation and model-based RL. In short, this survey provides both a practical overview for engineers wanting to implement emotions in their RL agents, and identifies challenges and directions for future emotion-RL research.	Arxiv
32	MEMe: An Accurate Maximum Entropy Method for Efficient Approximations in Large-Scale Machine Learning	Diego Granziol	2019-06-03 22:10:52	http://arxiv.org/abs/1906.01101v1	Efficient approximation lies at the heart of large-scale machine learning problems. In this paper, we propose a novel, robust maximum entropy algorithm, which is capable of dealing with hundreds of moments and allows for computationally efficient approximations. We showcase the usefulness of the proposed method, its equivalence to constrained Bayesian variational inference and demonstrate its superiority over existing approaches in two applications, namely, fast log determinant estimation and information-theoretic Bayesian optimisation.	Arxiv
33	Generalizing Machine Learning Evaluation through the Integration of Shannon Entropy and Rough Set Theory	Olga Cherednichenko	2024-04-18 21:22:42	http://arxiv.org/abs/2404.12511v1	This research paper delves into the innovative integration of Shannon entropy and rough set theory, presenting a novel approach to generalize the evaluation approach in machine learning. The conventional application of entropy, primarily focused on information uncertainty, is extended through its combination with rough set theory to offer a deeper insight into data's intrinsic structure and the interpretability of machine learning models. We introduce a comprehensive framework that synergizes the granularity of rough set theory with the uncertainty quantification of Shannon entropy, applied across a spectrum of machine learning algorithms. Our methodology is rigorously tested on various datasets, showcasing its capability to not only assess predictive performance but also to illuminate the underlying data complexity and model robustness. The results underscore the utility of this integrated approach in enhancing the evaluation landscape of machine learning, offering a multi-faceted perspective that balances accuracy with a profound understanding of data attributes and model dynamics. This paper contributes a groundbreaking perspective to machine learning evaluation, proposing a method that encapsulates a holistic view of model performance, thereby facilitating more informed decision-making in model selection and application.	Arxiv
34	ALERT-Transformer: Bridging Asynchronous and Synchronous Machine Learning for Real-Time Event-based Spatio-Temporal Data	Carmen Martin-Turrero	2024-02-02 13:17:19	http://arxiv.org/abs/2402.01393v3	We seek to enable classic processing of continuous ultra-sparse spatiotemporal data generated by event-based sensors with dense machine learning models. We propose a novel hybrid pipeline composed of asynchronous sensing and synchronous processing that combines several ideas: (1) an embedding based on PointNet models -- the ALERT module -- that can continuously integrate new and dismiss old events thanks to a leakage mechanism, (2) a flexible readout of the embedded data that allows to feed any downstream model with always up-to-date features at any sampling rate, (3) exploiting the input sparsity in a patch-based approach inspired by Vision Transformer to optimize the efficiency of the method. These embeddings are then processed by a transformer model trained for object and gesture recognition. Using this approach, we achieve performances at the state-of-the-art with a lower latency than competitors. We also demonstrate that our asynchronous model can operate at any desired sampling rate.	Arxiv
35	Learning Representations from Dendrograms	Morteza Haghir Chehreghani	2018-12-21 16:11:00	http://arxiv.org/abs/1812.09225v4	We propose unsupervised representation learning and feature extraction from dendrograms. The commonly used Minimax distance measures correspond to building a dendrogram with single linkage criterion, with defining specific forms of a level function and a distance function over that. Therefore, we extend this method to arbitrary dendrograms. We develop a generalized framework wherein different distance measures and representations can be inferred from different types of dendrograms, level functions and distance functions. Via an appropriate embedding, we compute a vector-based representation of the inferred distances, in order to enable many numerical machine learning algorithms to employ such distances. Then, to address the model selection problem, we study the aggregation of different dendrogram-based distances respectively in solution space and in representation space in the spirit of deep representations. In the first approach, for example for the clustering problem, we build a graph with positive and negative edge weights according to the consistency of the clustering labels of different objects among different solutions, in the context of ensemble methods. Then, we use an efficient variant of correlation clustering to produce the final clusters. In the second approach, we investigate the combination of different distances and features sequentially in the spirit of multi-layered architectures to obtain the final features. Finally, we demonstrate the effectiveness of our approach via several numerical studies.	Arxiv
36	Public Policymaking for International Agricultural Trade using Association Rules and Ensemble Machine Learning	Feras A. Batarseh	2021-11-15 02:58:03	http://arxiv.org/abs/2111.07508v1	International economics has a long history of improving our understanding of factors causing trade, and the consequences of free flow of goods and services across countries. The recent shocks to the free trade regime, especially trade disputes among major economies, as well as black swan events, such as trade wars and pandemics, raise the need for improved predictions to inform policy decisions. AI methods are allowing economists to solve such prediction problems in new ways. In this manuscript, we present novel methods that predict and associate food and agricultural commodities traded internationally. Association Rules (AR) analysis has been deployed successfully for economic scenarios at the consumer or store level, such as for market basket analysis. In our work however, we present analysis of imports and exports associations and their effects on commodity trade flows. Moreover, Ensemble Machine Learning methods are developed to provide improved agricultural trade predictions, outlier events' implications, and quantitative pointers to policy makers.	Arxiv
37	Unsupervised Representation Learning with Minimax Distance Measures	Morteza Haghir Chehreghani	2019-04-27 16:13:08	http://arxiv.org/abs/1904.13223v3	We investigate the use of Minimax distances to extract in a nonparametric way the features that capture the unknown underlying patterns and structures in the data. We develop a general-purpose and computationally efficient framework to employ Minimax distances with many machine learning methods that perform on numerical data. We study both computing the pairwise Minimax distances for all pairs of objects and as well as computing the Minimax distances of all the objects to/from a fixed (test) object. We first efficiently compute the pairwise Minimax distances between the objects, using the equivalence of Minimax distances over a graph and over a minimum spanning tree constructed on that. Then, we perform an embedding of the pairwise Minimax distances into a new vector space, such that their squared Euclidean distances in the new space equal to the pairwise Minimax distances in the original space. We also study the case of having multiple pairwise Minimax matrices, instead of a single one. Thereby, we propose an embedding via first summing up the centered matrices and then performing an eigenvalue decomposition to obtain the relevant features. In the following, we study computing Minimax distances from a fixed (test) object which can be used for instance in K-nearest neighbor search. Similar to the case of all-pair pairwise Minimax distances, we develop an efficient and general-purpose algorithm that is applicable with any arbitrary base distance measure. Moreover, we investigate in detail the edges selected by the Minimax distances and thereby explore the ability of Minimax distances in detecting outlier objects. Finally, for each setting, we perform several experiments to demonstrate the effectiveness of our framework.	Arxiv
38	Automatic Machine Learning by Pipeline Synthesis using Model-Based Reinforcement Learning and a Grammar	Iddo Drori	2019-05-24 17:27:10	http://arxiv.org/abs/1905.10345v1	Automatic machine learning is an important problem in the forefront of machine learning. The strongest AutoML systems are based on neural networks, evolutionary algorithms, and Bayesian optimization. Recently AlphaD3M reached state-of-the-art results with an order of magnitude speedup using reinforcement learning with self-play. In this work we extend AlphaD3M by using a pipeline grammar and a pre-trained model which generalizes from many different datasets and similar tasks. Our results demonstrate improved performance compared with our earlier work and existing methods on AutoML benchmark datasets for classification and regression tasks. In the spirit of reproducible research we make our data, models, and code publicly available.	Arxiv
39	Beyond Volume: The Impact of Complex Healthcare Data on the Machine Learning Pipeline	Keith Feldman	2017-06-01 20:34:41	http://arxiv.org/abs/1706.01513v2	From medical charts to national census, healthcare has traditionally operated under a paper-based paradigm. However, the past decade has marked a long and arduous transformation bringing healthcare into the digital age. Ranging from electronic health records, to digitized imaging and laboratory reports, to public health datasets, today, healthcare now generates an incredible amount of digital information. Such a wealth of data presents an exciting opportunity for integrated machine learning solutions to address problems across multiple facets of healthcare practice and administration. Unfortunately, the ability to derive accurate and informative insights requires more than the ability to execute machine learning models. Rather, a deeper understanding of the data on which the models are run is imperative for their success. While a significant effort has been undertaken to develop models able to process the volume of data obtained during the analysis of millions of digitalized patient records, it is important to remember that volume represents only one aspect of the data. In fact, drawing on data from an increasingly diverse set of sources, healthcare data presents an incredibly complex set of attributes that must be accounted for throughout the machine learning pipeline. This chapter focuses on highlighting such challenges, and is broken down into three distinct components, each representing a phase of the pipeline. We begin with attributes of the data accounted for during preprocessing, then move to considerations during model building, and end with challenges to the interpretation of model output. For each component, we present a discussion around data as it relates to the healthcare domain and offer insight into the challenges each may impose on the efficiency of machine learning techniques.	Arxiv
40	Explanatory machine learning for sequential human teaching	Lun Ai	2022-05-20 15:23:46	http://arxiv.org/abs/2205.10250v2	The topic of comprehensibility of machine-learned theories has recently drawn increasing attention. Inductive Logic Programming (ILP) uses logic programming to derive logic theories from small data based on abduction and induction techniques. Learned theories are represented in the form of rules as declarative descriptions of obtained knowledge. In earlier work, the authors provided the first evidence of a measurable increase in human comprehension based on machine-learned logic rules for simple classification tasks. In a later study, it was found that the presentation of machine-learned explanations to humans can produce both beneficial and harmful effects in the context of game learning. We continue our investigation of comprehensibility by examining the effects of the ordering of concept presentations on human comprehension. In this work, we examine the explanatory effects of curriculum order and the presence of machine-learned explanations for sequential problem-solving. We show that 1) there exist tasks A and B such that learning A before B has a better human comprehension with respect to learning B before A and 2) there exist tasks A and B such that the presence of explanations when learning A contributes to improved human comprehension when subsequently learning B. We propose a framework for the effects of sequential teaching on comprehension based on an existing definition of comprehensibility and provide evidence for support from data collected in human trials. Empirical results show that sequential teaching of concepts with increasing complexity a) has a beneficial effect on human comprehension and b) leads to human re-discovery of divide-and-conquer problem-solving strategies, and c) studying machine-learned explanations allows adaptations of human problem-solving strategy with better performance.	Arxiv
41	Reproducibility in Machine Learning for Health	Matthew B. A. McDermott	2019-07-02 15:46:46	http://arxiv.org/abs/1907.01463v1	Machine learning algorithms designed to characterize, monitor, and intervene on human health (ML4H) are expected to perform safely and reliably when operating at scale, potentially outside strict human supervision. This requirement warrants a stricter attention to issues of reproducibility than other fields of machine learning.   In this work, we conduct a systematic evaluation of over 100 recently published ML4H research papers along several dimensions related to reproducibility. We find that the field of ML4H compares poorly to more established machine learning fields, particularly concerning data and code accessibility. Finally, drawing from success in other fields of science, we propose recommendations to data providers, academic publishers, and the ML4H research community in order to promote reproducible research moving forward.	Arxiv
42	ML-Schema: Exposing the Semantics of Machine Learning with Schemas and Ontologies	Gustavo Correa Publio	2018-07-14 08:07:31	http://arxiv.org/abs/1807.05351v1	The ML-Schema, proposed by the W3C Machine Learning Schema Community Group, is a top-level ontology that provides a set of classes, properties, and restrictions for representing and interchanging information on machine learning algorithms, datasets, and experiments. It can be easily extended and specialized and it is also mapped to other more domain-specific ontologies developed in the area of machine learning and data mining. In this paper we overview existing state-of-the-art machine learning interchange formats and present the first release of ML-Schema, a canonical format resulted of more than seven years of experience among different research institutions. We argue that exposing semantics of machine learning algorithms, models, and experiments through a canonical format may pave the way to better interpretability and to realistically achieve the full interoperability of experiments regardless of platform or adopted workflow solution.	Arxiv
43	Stop Explaining Black Box Machine Learning Models for High Stakes Decisions and Use Interpretable Models Instead	Cynthia Rudin	2018-11-26 03:00:25	http://arxiv.org/abs/1811.10154v3	Black box machine learning models are currently being used for high stakes decision-making throughout society, causing problems throughout healthcare, criminal justice, and in other domains. People have hoped that creating methods for explaining these black box models will alleviate some of these problems, but trying to \textit{explain} black box models, rather than creating models that are \textit{interpretable} in the first place, is likely to perpetuate bad practices and can potentially cause catastrophic harm to society. There is a way forward -- it is to design models that are inherently interpretable. This manuscript clarifies the chasm between explaining black boxes and using inherently interpretable models, outlines several key reasons why explainable black boxes should be avoided in high-stakes decisions, identifies challenges to interpretable machine learning, and provides several example applications where interpretable models could potentially replace black box models in criminal justice, healthcare, and computer vision.	Arxiv
44	A Framework for Implementing Machine Learning on Omics Data	Geoffroy Dubourg-Felonneau	2018-11-26 15:35:57	http://arxiv.org/abs/1811.10455v1	The potential benefits of applying machine learning methods to -omics data are becoming increasingly apparent, especially in clinical settings. However, the unique characteristics of these data are not always well suited to machine learning techniques. These data are often generated across different technologies in different labs, and frequently with high dimensionality. In this paper we present a framework for combining -omics data sets, and for handling high dimensional data, making -omics research more accessible to machine learning applications. We demonstrate the success of this framework through integration and analysis of multi-analyte data for a set of 3,533 breast cancers. We then use this data-set to predict breast cancer patient survival for individuals at risk of an impending event, with higher accuracy and lower variance than methods trained on individual data-sets. We hope that our pipelines for data-set generation and transformation will open up -omics data to machine learning researchers. We have made these freely available for noncommercial use at www.ccg.ai.	Arxiv
45	Teaching Uncertainty Quantification in Machine Learning through Use Cases	Matias Valdenegro-Toro	2021-08-19 14:22:17	http://arxiv.org/abs/2108.08712v1	Uncertainty in machine learning is not generally taught as general knowledge in Machine Learning course curricula. In this paper we propose a short curriculum for a course about uncertainty in machine learning, and complement the course with a selection of use cases, aimed to trigger discussion and let students play with the concepts of uncertainty in a programming setting. Our use cases cover the concept of output uncertainty, Bayesian neural networks and weight distributions, sources of uncertainty, and out of distribution detection. We expect that this curriculum and set of use cases motivates the community to adopt these important concepts into courses for safety in AI.	Arxiv
46	The Scientific Method in the Science of Machine Learning	Jessica Zosa Forde	2019-04-24 17:01:43	http://arxiv.org/abs/1904.10922v1	In the quest to align deep learning with the sciences to address calls for rigor, safety, and interpretability in machine learning systems, this contribution identifies key missing pieces: the stages of hypothesis formulation and testing, as well as statistical and systematic uncertainty estimation -- core tenets of the scientific method. This position paper discusses the ways in which contemporary science is conducted in other domains and identifies potentially useful practices. We present a case study from physics and describe how this field has promoted rigor through specific methodological practices, and provide recommendations on how machine learning researchers can adopt these practices into the research ecosystem. We argue that both domain-driven experiments and application-agnostic questions of the inner workings of fundamental building blocks of machine learning models ought to be examined with the tools of the scientific method, to ensure we not only understand effect, but also begin to understand cause, which is the raison d'Ãªtre of science.	Arxiv
47	TapNet: Neural Network Augmented with Task-Adaptive Projection for Few-Shot Learning	Sung Whan Yoon	2019-05-16 06:21:28	http://arxiv.org/abs/1905.06549v2	Handling previously unseen tasks after given only a few training examples continues to be a tough challenge in machine learning. We propose TapNets, neural networks augmented with task-adaptive projection for improved few-shot learning. Here, employing a meta-learning strategy with episode-based training, a network and a set of per-class reference vectors are learned across widely varying tasks. At the same time, for every episode, features in the embedding space are linearly projected into a new space as a form of quick task-specific conditioning. The training loss is obtained based on a distance metric between the query and the reference vectors in the projection space. Excellent generalization results in this way. When tested on the Omniglot, miniImageNet and tieredImageNet datasets, we obtain state of the art classification accuracies under various few-shot scenarios.	Arxiv
48	Multimodal Machine Learning for Automated ICD Coding	Keyang Xu	2018-10-31 15:39:32	http://arxiv.org/abs/1810.13348v4	This study presents a multimodal machine learning model to predict ICD-10 diagnostic codes. We developed separate machine learning models that can handle data from different modalities, including unstructured text, semi-structured text and structured tabular data. We further employed an ensemble method to integrate all modality-specific models to generate ICD-10 codes. Key evidence was also extracted to make our prediction more convincing and explainable. We used the Medical Information Mart for Intensive Care III (MIMIC -III) dataset to validate our approach. For ICD code prediction, our best-performing model (micro-F1 = 0.7633, micro-AUC = 0.9541) significantly outperforms other baseline models including TF-IDF (micro-F1 = 0.6721, micro-AUC = 0.7879) and Text-CNN model (micro-F1 = 0.6569, micro-AUC = 0.9235). For interpretability, our approach achieves a Jaccard Similarity Coefficient (JSC) of 0.1806 on text data and 0.3105 on tabular data, where well-trained physicians achieve 0.2780 and 0.5002 respectively.	Arxiv
