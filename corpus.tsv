id	titre	auteur	date	url	texte	type
0	I switched to Machine Learning and I am LOST	Hertz314159	2025-10-29 01:46:28	https://reddit.com/r/learnmachinelearning/comments/1oiqsax/i_switched_to_machine_learning_and_i_am_lost/	I switched to Machine Learning and I am LOST Hello everybody, I'm a bit lost and could use some help.  I'm in a 5-year Computer Science program. The first 3 years cover general programming and math concepts, and the last two are for specialization. We had two specializations (Software and Network Engineering), but this year a new one opened called AI, which focuses on AI logic and Machine Learning. I found this really exciting, so even after learning Back-End development last year, I chose to enroll in this new track.  I have a good background in programming with C++, Java, Go, and Python. I've used Python for data manipulation with Pandas and NumPy, I've studied Data Structures and Algorithms, and I solve problems on LeetCode and Codeforces.  I've seen some roadmaps; some say I should start with math (Linear Algebra, Statistics, and Probability), while others say to start with coding.  By the end of the study year (in about 8 months), I need to complete a final project: creating a model that diagnoses patients based on symptoms.  So, how should I start my journey?	Reddit
1	Best resources to learn Machine Learning deeply in 2‚Äì3 months?	vansh596	2025-08-18 13:53:27	https://reddit.com/r/learnmachinelearning/comments/1mtjv2v/best_resources_to_learn_machine_learning_deeply/	Best resources to learn Machine Learning deeply in 2‚Äì3 months? Hey everyone,  I‚Äôm planning to spend the next 2‚Äì3 months fully focused on Machine Learning. I already know Python, NumPy, Pandas, Matplotlib, Plotly, and the math side (linear algebra, probability, calculus basics), so I‚Äôm not starting from zero. The only part I really want to dive into now is Machine Learning itself.  What I‚Äôm looking for are resources that go deep and clear all concepts properly ‚Äî not just a surface-level intro. Something that makes sure I don‚Äôt miss anything important, from supervised/unsupervised learning to neural networks, optimization, and practical applications.  Could you suggest:  Courses / books / YouTube playlists that explain concepts thoroughly.  Practice resources / project ideas to actually apply what I learn.  Any structured study plan or roadmap you personally found effective.   Basically, if you had to master ML in 2‚Äì3 months with full dedication, what resources would you rely on?  Thanks a lot üôè 	Reddit
2	Is machine learning a good career in 2025?	stanley_john	2025-08-13 13:07:19	https://reddit.com/r/learnmachinelearning/comments/1mp1fnc/is_machine_learning_a_good_career_in_2025/	Is machine learning a good career in 2025? 	Reddit
3	"I hate ""my"" ""field"" (machine learning)"	Substantial-Art-2238	2025-04-17 10:23:23	https://reddit.com/r/PhD/comments/1k17rbr/i_hate_my_field_machine_learning/	"I hate ""my"" ""field"" (machine learning) A lot of people (like me) dive  into ML thinking it's about understanding intelligence, learning, or even just clever math ‚Äî and then they wake up buried under a pile of frameworks, configs, random seeds, hyperparameter grids, and Google Colab crashes. And the worst part? No one tells you how undefined the field really is until you're *knee-deep in the swamp.*  In mathematics:  * There's structure. Rigor. A kind of calm beauty in clarity. * You can prove something and *know* it‚Äôs true. * You explore the unknown, yes ‚Äî but on solid ground.  In ML:  * You fumble through a foggy mess of tunable knobs and lucky guesses. * ‚ÄúReproducibility‚Äù is a fantasy. * Half the field is just ‚Äúwhat worked better for us‚Äù and the other half is trying to explain it *after* the fact. * Nobody *really* knows why half of it works, and yet they act like they do."	Reddit
4	Machine Learning Hiring üí™	Zealousideal_Bit_177	2025-09-13 12:32:36	https://reddit.com/r/Btechtards/comments/1nfu6b8/machine_learning_hiring/	Machine Learning Hiring üí™ 	Reddit
5	Changing Data Sources in the Age of Machine Learning for Official Statistics	Cedric De Boom	2023-06-07 11:08:12	http://arxiv.org/abs/2306.04338v1	Data science has become increasingly essential for the production of official statistics, as it enables the automated collection, processing, and analysis of large amounts of data. With such data science practices in place, it enables more timely, more insightful and more flexible reporting. However, the quality and integrity of data-science-driven statistics rely on the accuracy and reliability of the data sources and the machine learning techniques that support them. In particular, changes in data sources are inevitable to occur and pose significant risks that are crucial to address in the context of machine learning for official statistics.   This paper gives an overview of the main risks, liabilities, and uncertainties associated with changing data sources in the context of machine learning for official statistics. We provide a checklist of the most prevalent origins and causes of changing data sources; not only on a technical level but also regarding ownership, ethics, regulation, and public perception. Next, we highlight the repercussions of changing data sources on statistical reporting. These include technical effects such as concept drift, bias, availability, validity, accuracy and completeness, but also the neutrality and potential discontinuation of the statistical offering. We offer a few important precautionary measures, such as enhancing robustness in both data sourcing and statistical techniques, and thorough monitoring. In doing so, machine learning-based official statistics can maintain integrity, reliability, consistency, and relevance in policy-making, decision-making, and public discourse.	Arxiv
6	DOME: Recommendations for supervised machine learning validation in biology	Ian Walsh	2020-06-25 12:01:39	http://arxiv.org/abs/2006.16189v4	Modern biology frequently relies on machine learning to provide predictions and improve decision processes. There have been recent calls for more scrutiny on machine learning performance and possible limitations. Here we present a set of community-wide recommendations aiming to help establish standards of supervised machine learning validation in biology. Adopting a structured methods description for machine learning based on data, optimization, model, evaluation (DOME) will aim to help both reviewers and readers to better understand and assess the performance and limitations of a method or outcome. The recommendations are formulated as questions to anyone wishing to pursue implementation of a machine learning algorithm. Answers to these questions can be easily included in the supplementary material of published papers.	Arxiv
7	Learning Curves for Decision Making in Supervised Machine Learning: A Survey	Felix Mohr	2022-01-28 14:34:32	http://arxiv.org/abs/2201.12150v2	Learning curves are a concept from social sciences that has been adopted in the context of machine learning to assess the performance of a learning algorithm with respect to a certain resource, e.g., the number of training examples or the number of training iterations. Learning curves have important applications in several machine learning contexts, most notably in data acquisition, early stopping of model training, and model selection. For instance, learning curves can be used to model the performance of the combination of an algorithm and its hyperparameter configuration, providing insights into their potential suitability at an early stage and often expediting the algorithm selection process. Various learning curve models have been proposed to use learning curves for decision making. Some of these models answer the binary decision question of whether a given algorithm at a certain budget will outperform a certain reference performance, whereas more complex models predict the entire learning curve of an algorithm. We contribute a framework that categorises learning curve approaches using three criteria: the decision-making situation they address, the intrinsic learning curve question they answer and the type of resources they use. We survey papers from the literature and classify them into this framework.	Arxiv
8	Active learning for data streams: a survey	Davide Cacciarelli	2023-02-17 14:24:13	http://arxiv.org/abs/2302.08893v4	Online active learning is a paradigm in machine learning that aims to select the most informative data points to label from a data stream. The problem of minimizing the cost associated with collecting labeled observations has gained a lot of attention in recent years, particularly in real-world applications where data is only available in an unlabeled form. Annotating each observation can be time-consuming and costly, making it difficult to obtain large amounts of labeled data. To overcome this issue, many active learning strategies have been proposed in the last decades, aiming to select the most informative observations for labeling in order to improve the performance of machine learning models. These approaches can be broadly divided into two categories: static pool-based and stream-based active learning. Pool-based active learning involves selecting a subset of observations from a closed pool of unlabeled data, and it has been the focus of many surveys and literature reviews. However, the growing availability of data streams has led to an increase in the number of approaches that focus on online active learning, which involves continuously selecting and labeling observations as they arrive in a stream. This work aims to provide an overview of the most recently proposed approaches for selecting the most informative observations from data streams in real time. We review the various techniques that have been proposed and discuss their strengths and limitations, as well as the challenges and opportunities that exist in this area of research.	Arxiv
9	Physics-Inspired Interpretability Of Machine Learning Models	Maximilian P Niroomand	2023-04-05 11:35:17	http://arxiv.org/abs/2304.02381v2	The ability to explain decisions made by machine learning models remains one of the most significant hurdles towards widespread adoption of AI in highly sensitive areas such as medicine, cybersecurity or autonomous driving. Great interest exists in understanding which features of the input data prompt model decision making. In this contribution, we propose a novel approach to identify relevant features of the input data, inspired by methods from the energy landscapes field, developed in the physical sciences. By identifying conserved weights within groups of minima of the loss landscapes, we can identify the drivers of model decision making. Analogues to this idea exist in the molecular sciences, where coordinate invariants or order parameters are employed to identify critical features of a molecule. However, no such approach exists for machine learning loss landscapes. We will demonstrate the applicability of energy landscape methods to machine learning models and give examples, both synthetic and from the real world, for how these methods can help to make models more interpretable.	Arxiv
